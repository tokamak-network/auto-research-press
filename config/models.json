{
  "_comment": "Model configuration using 3-tier structure: Reasoning (Opus) > Support (Sonnet) > Light (Flash). Gemini models use higher max_tokens due to thinking token overhead.",
  "tiers": {
    "reasoning": {
      "primary": {"model": "gemini-2.5-pro", "provider": "google"},
      "fallback": [
        {"model": "claude-opus-4-6", "provider": "anthropic"},
        {"model": "claude-sonnet-4-5", "provider": "anthropic"}
      ]
    },
    "support": {
      "primary": {"model": "claude-sonnet-4-5", "provider": "anthropic"},
      "fallback": [
        {"model": "claude-haiku-4-5", "provider": "anthropic"}
      ]
    },
    "light": {
      "primary": {"model": "gemini-2.5-flash", "provider": "google"},
      "fallback": [
        {"model": "claude-haiku-4-5", "provider": "anthropic"},
        {"model": "claude-sonnet-4-5", "provider": "anthropic"}
      ]
    }
  },
  "roles": {
    "writer": { "tier": "reasoning", "temperature": 0.7, "max_tokens": 16384 },
    "lead_author": { "tier": "reasoning", "temperature": 0.7, "max_tokens": 16384 },
    "paper_writer": { "tier": "reasoning", "temperature": 0.7, "max_tokens": 16384 },
    "research_planner": { "tier": "light", "temperature": 0.7, "max_tokens": 8192 },
    "team_composer": { "tier": "light", "temperature": 0.7, "max_tokens": 8192 },
    "moderator": { "tier": "light", "temperature": 0.3, "max_tokens": 8192 },
    "reviewer": { "tier": "reasoning", "temperature": 0.3, "max_tokens": 8192 },
    "reviewer_rotation": [
      {"provider": "google", "model": "gemini-2.5-pro"},
      {"provider": "anthropic", "model": "claude-sonnet-4-5"},
      {"provider": "anthropic", "model": "claude-sonnet-4-5"}
    ],

    "coauthor": { "tier": "support", "temperature": 0.7, "max_tokens": 4096 },
    "integration_editor": { "tier": "light", "temperature": 0.5, "max_tokens": 8192 },
    "research_notes": { "tier": "light", "temperature": 0.5, "max_tokens": 8192 },
    "citation_verifier": { "tier": "light", "temperature": 0.5, "max_tokens": 8192 },

    "author_response": { "tier": "light", "temperature": 0.7, "max_tokens": 4096 },
    "desk_editor": { "tier": "light", "temperature": 0.1, "max_tokens": 2048 },
    "categorizer": { "tier": "light", "temperature": 0.3, "max_tokens": 2048 },
    "title_generator": { "tier": "light", "temperature": 0.7, "max_tokens": 256 }
  },
  "provider_config": {
    "llm": {
      "env_key": "LITELLM_MASTER_KEY",
      "env_base_url": "LLM_BASE_URL"
    },
    "anthropic": {
      "env_key": "ANTHROPIC_API_KEY",
      "env_key_alt": "ANTHROPIC_AUTH_TOKEN",
      "env_base_url": "ANTHROPIC_BASE_URL"
    },
    "openai": {
      "env_key": "LITELLM_MASTER_KEY",
      "env_base_url": "LLM_BASE_URL"
    },
    "google": {
      "env_key": "GOOGLE_API_KEY",
      "env_base_url": "GOOGLE_BASE_URL"
    },
    "deepseek": {
      "env_key": "LITELLM_MASTER_KEY",
      "env_base_url": "LLM_BASE_URL"
    }
  },
  "pricing": {
    "gemini-2.5-flash": {"input": 0.15, "output": 0.60},
    "gemini-2.5-pro": {"input": 1.25, "output": 5.0},
    "gemini-3-pro": {"input": 2.0, "output": 8.0},
    "gemini-3-flash": {"input": 0.10, "output": 0.40},
    "deepseek-v3.2": {"input": 1.0, "output": 4.0},
    "claude-opus-4-6": {"input": 5.0, "output": 25.0},
    "claude-sonnet-4-5": {"input": 3.0, "output": 15.0},
    "claude-haiku-4-5": {"input": 1.0, "output": 5.0},
    "gpt-5.2-pro": {"input": 2.0, "output": 8.0}
  }
}
