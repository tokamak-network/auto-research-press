{
  "round": 1,
  "manuscript_version": "v1",
  "word_count": 2683,
  "reviews": [
    {
      "specialist": "expert_1",
      "specialist_name": "AI/ML for Financial Market Prediction and Algorithmic Trading",
      "provider": "anthropic",
      "model": "claude-opus-4-6",
      "scores": {
        "accuracy": 4,
        "completeness": 5,
        "clarity": 6,
        "novelty": 2,
        "rigor": 2,
        "citations": 3
      },
      "average": 3.7,
      "summary": "This manuscript reads as a broad survey or industry report rather than a research contribution, offering no original experiments, no novel framework, and no rigorous evaluation of any AI/ML methodology applied to cryptocurrency markets. The claims about model performance are entirely derivative and lack specificity, while the citation base is thin, heavily reliant on non-peer-reviewed sources (Forbes, Token Metrics, arXiv preprints), and contains multiple '[citation needed]' placeholders that signal incomplete scholarship. From an AI/ML for financial market prediction standpoint, the paper fails to engage meaningfully with the technical substance of the architectures, evaluation protocols, or failure modes it purports to discuss.",
      "strengths": [
        "The paper covers a reasonable breadth of topics\u2014prediction, trading microstructure, security, regulation\u2014providing a useful organizational scaffold for the AI-crypto intersection.",
        "The writing is generally clear and accessible, with logical section progression that would orient a non-specialist reader.",
        "The discussion of reflexivity and algorithmic herding (drawing on Krafft et al. [7]) is a worthwhile point that is often underappreciated in the crypto-AI literature."
      ],
      "weaknesses": [
        "There is zero methodological rigor: no original experiments, no quantitative results, no specific evaluation metrics (Sharpe ratio, RMSE, directional accuracy, etc.), no discussion of train/test splits, walk-forward validation, or data leakage\u2014all of which are fundamental to assessing any claim about AI-driven crypto prediction or trading performance. Statements like 'hybrid CNN-LSTM models achieved superior performance' are vacuous without reporting actual metrics, datasets, time periods, and baselines.",
        "The citation base is critically weak for a research manuscript. Multiple '[citation needed]' placeholders remain, several key references are industry blog posts (Token Metrics [15]) or journalistic pieces (Forbes [13]) rather than peer-reviewed work, and highly relevant foundational literature is entirely absent\u2014e.g., no citation of Bao et al. (2017) on deep learning for stock prediction, no mention of FinBERT or crypto-specific sentiment models, no reference to key RL-for-trading papers (Deng et al., 2016; Jiang et al., 2017), and no engagement with the extensive literature on non-stationarity testing (e.g., regime-switching models, concept drift detection).",
        "The paper makes no original contribution. It synthesizes existing work at a very high level without adding a new framework, taxonomy, empirical finding, or even a structured critical comparison of methods. The 'Future Predictions' section is entirely speculative with no grounding in quantitative trend analysis or formal scenario modeling."
      ],
      "suggestions": [
        "If this is intended as a survey/review, it must engage deeply with the technical details of the ML architectures discussed. For each method class (LSTM, CNN-LSTM, Transformer, RL), provide a structured comparison table with reported metrics, datasets, prediction horizons, and known limitations. Critically assess backtesting methodologies used in cited studies\u2014do they use walk-forward validation? Do they account for transaction costs and slippage? Is there evidence of look-ahead bias or survivorship bias?",
        "Replace industry blog posts and Forbes articles with peer-reviewed sources. Engage with the substantial body of work on: (a) transformer architectures for financial time series (e.g., Temporal Fusion Transformers, Informer), (b) crypto-specific sentiment analysis using FinBERT or domain-adapted LLMs, (c) reinforcement learning for portfolio optimization in crypto (e.g., Jiang & Liang, 2017), and (d) the well-documented challenges of non-stationarity and regime change in crypto markets. Remove all '[citation needed]' placeholders\u2014either find the citation or remove the claim.",
        "Define a clear, narrow contribution. For a short paper, one viable path would be a critical methodological review of backtesting practices in crypto-AI papers, documenting the prevalence of overfitting, data leakage, and unrealistic assumptions. Another would be a structured comparison of LLM-based vs. traditional NLP sentiment signals for crypto prediction. The current breadth-without-depth approach is unsuitable for a research venue."
      ],
      "detailed_feedback": "From the perspective of AI/ML for financial market prediction and algorithmic trading, this manuscript has fundamental deficiencies that prevent it from making a meaningful research contribution. The most critical issue is the complete absence of technical depth regarding the ML methods discussed. When the paper claims CNN-LSTM hybrids outperform single architectures for Bitcoin prediction, a reviewer needs to know: outperform on what metric? Over what time horizon? On what dataset and time period? With what validation protocol? The cited Frontiers paper [12/14] (which appears to be cited twice as two separate references, suggesting carelessness) presumably contains these details, but the manuscript's failure to report or critically assess them renders the claim scientifically meaningless. Similarly, the discussion of transformer-based models and LLMs for crypto prediction is entirely superficial\u2014there is no discussion of attention mechanisms' suitability for financial time series, no mention of positional encoding challenges for irregular time series, no assessment of whether LLM-based sentiment signals provide statistically significant alpha after transaction costs, and no acknowledgment of the well-documented tendency for LLMs to hallucinate or produce overconfident predictions. The backtesting and evaluation methodology discussion is essentially nonexistent, which is perhaps the most damaging omission. The crypto-AI literature is rife with papers reporting spectacular backtest returns that fail catastrophically in live trading due to overfitting, look-ahead bias, unrealistic fill assumptions, and failure to account for market impact. A serious review paper would critically examine these methodological pitfalls. The security and fraud detection section, while topically relevant, similarly lacks technical substance\u2014graph neural networks for blockchain forensics are mentioned in passing without any discussion of their architecture, training data requirements, false positive rates, or adversarial robustness. The regulatory and ethical sections, while well-intentioned, are generic and could apply to AI in any financial market rather than offering crypto-specific insights. Overall, this reads as an extended blog post or executive briefing rather than a research manuscript. For any venue with peer review standards, it would require a fundamental reconceptualization around a specific, defensible contribution supported by either original empirical work or a rigorous, technically detailed critical review of existing methods.",
      "tokens": 6868
    },
    {
      "specialist": "expert_2",
      "specialist_name": "Cryptocurrency Market Microstructure and Digital Asset Economics",
      "provider": "anthropic",
      "model": "claude-opus-4-6",
      "scores": {
        "accuracy": 4,
        "completeness": 4,
        "clarity": 6,
        "novelty": 2,
        "rigor": 3,
        "citations": 3
      },
      "average": 3.7,
      "summary": "This manuscript reads as a broad survey-style overview rather than a focused short paper with a clear contribution. It lacks substantive engagement with cryptocurrency market microstructure\u2014the purported core topic\u2014and relies heavily on tangentially related or non-peer-reviewed sources while omitting the most relevant literature on DEX/CEX dynamics, MEV, on-chain order flow, and regulatory frameworks like MiCA.",
      "strengths": [
        "The paper is clearly written and well-organized, with logical section headings that guide the reader through the AI-crypto landscape.",
        "The identification of reflexivity in AI-driven crypto markets (Section on price prediction) is a genuinely important point that deserves more development.",
        "The paper correctly flags the arms race between AI-powered attack and defense vectors in crypto security as a defining dynamic."
      ],
      "weaknesses": [
        "The paper contains virtually no substantive discussion of actual market microstructure: there is no treatment of DEX vs. CEX dynamics, no discussion of MEV (Maximal Extractable Value) extraction by AI agents, no analysis of on-chain order flow or mempool dynamics, and only a superficial mention of AMMs without engaging with their pricing mechanics (e.g., constant product functions, concentrated liquidity in Uniswap v3). The single sentence on AMMs is inadequate for a paper claiming to address market microstructure effects.",
        "The regulatory discussion is strikingly shallow\u2014there is no mention of MiCA (Markets in Crypto-Assets Regulation), no discussion of SEC enforcement actions (e.g., against Binance, Coinbase, or specific DeFi protocols), no treatment of stablecoin regulation (e.g., the EU's stablecoin provisions or proposed US legislation), and no analysis of how these specific regulatory developments interact with AI deployment. The section contains five consecutive '[citation needed]' markers, signaling that the claims are entirely unsupported.",
        "The citation base is weak and largely tangential. Key references include a paper on Indian stock market power laws [8], a general paper on AI in education [11], a general paper on green AI for smart cities [4], and a general paper on AI in auditing [5]\u2014none of which are specific to crypto market microstructure. The most crypto-specific references are a 2018 arXiv preprint on correlation networks [6], a Token Metrics blog post [15], and a Forbes article [13]. Critical works in the field are entirely absent: Daian et al. (2020) 'Flash Boys 2.0' on MEV, Capponi & Jia (2021) on AMM design, Park (2021) on DeFi market microstructure, Barbon & Ranaldo (2021) on crypto market quality, and the extensive literature on wash trading detection (e.g., Cong et al. 2023, Victor & Weintraud 2021) are all missing."
      ],
      "suggestions": [
        "Narrow the scope dramatically. For a short paper, pick one concrete contribution\u2014e.g., how AI agents interact with MEV extraction on Ethereum, or how AI-driven wash trading detection performs on DEXs vs. CEXs\u2014and develop it with technical depth. The current paper tries to cover prediction, trading, security, regulation, sustainability, and education, resulting in superficial treatment of everything.",
        "Replace tangential citations with domain-specific literature. At minimum, cite Daian et al. (2020) on MEV/frontrunning, Capponi & Jia (2021) or Aoyagi (2020) on AMM microstructure, Makarov & Schoar (2020) on crypto arbitrage and price efficiency, and Cong et al. (2023) on crypto wash trading. The five '[citation needed]' markers in the regulatory section must be resolved with actual references to MiCA text, SEC enforcement orders, or FATF guidance.",
        "Engage with the technical specifics of how AI agents actually operate on-chain. Discuss how reinforcement learning agents interact with mempool visibility, how sandwich attacks are executed by MEV bots, how AI-driven liquidation bots operate in DeFi lending protocols (Aave, Compound), and what the empirical evidence shows about AI's impact on DEX spreads and slippage. This would transform the paper from a general overview into a genuine contribution to the market microstructure literature."
      ],
      "detailed_feedback": "From the perspective of cryptocurrency market microstructure and digital asset economics, this manuscript has fundamental gaps that prevent it from making a meaningful contribution. The most critical omission is the complete absence of MEV (Maximal Extractable Value) analysis\u2014arguably the single most important intersection of AI and crypto market microstructure. Since Daian et al.'s seminal 'Flash Boys 2.0' work, the literature has extensively documented how AI-powered bots extract value through frontrunning, sandwich attacks, and arbitrage on DEXs, with Flashbots data showing billions of dollars in cumulative MEV extraction on Ethereum alone. Any paper claiming to analyze AI's impact on crypto market microstructure that does not discuss MEV is fundamentally incomplete. The paper's treatment of AMMs consists of a single sentence noting that 'algorithmic pricing functions replace traditional order book dynamics'\u2014this dramatically understates the complexity and importance of AMM design, concentrated liquidity provision, impermanent loss, and how AI agents optimize liquidity provision strategies. The distinction between CEX and DEX microstructure is never drawn, despite these being fundamentally different market structures with different implications for AI deployment. On the regulatory front, the paper's claims are almost entirely unsupported. The absence of any discussion of MiCA\u2014the most comprehensive crypto regulatory framework globally, which explicitly addresses algorithmic trading and market manipulation\u2014is a serious oversight. Similarly, SEC enforcement actions against major exchanges and the ongoing debate about whether DeFi protocols constitute exchanges or broker-dealers have direct implications for how AI trading systems can legally operate. The paper's discussion of wash trading detection mentions it only in passing, despite this being one of the most active areas of AI application in crypto markets, with sophisticated approaches using graph neural networks on transaction data (see Cong et al. 2023). The future predictions section is speculative and generic, offering no quantitative projections or scenario analysis. Claims about autonomous AI agents in DeFi are presented without reference to existing implementations (e.g., Autonolas, Fetch.ai) or the technical challenges of on-chain AI execution. The systemic risk implications\u2014which could be the paper's most valuable contribution\u2014are mentioned but never analyzed with any rigor. What would happen if multiple AI agents simultaneously attempted to liquidate positions in a DeFi lending protocol? How do AI-driven arbitrage bots affect cross-venue price convergence between CEXs and DEXs? These are tractable questions with available data that the paper could address but does not. The reliance on a Forbes article and a Token Metrics blog post as primary sources for market microstructure claims is inappropriate for academic work, even in a short paper format.",
      "tokens": 6998
    }
  ],
  "overall_average": 3.7,
  "moderator_decision": {
    "decision": "MAJOR_REVISION",
    "confidence": 5,
    "meta_review": "Both reviewers converge on the same fundamental diagnosis: this manuscript is a shallow, overly broad survey that lacks any original contribution, rigorous methodology, or adequate engagement with the relevant literature. The average score of 3.7/10 reflects genuine and substantive deficiencies, not reviewer miscalibration. The criticisms are not nitpicking\u2014they identify structural problems: no original experiments or framework, multiple unresolved '[citation needed]' placeholders, reliance on non-peer-reviewed sources (Forbes, blog posts) over foundational literature, and superficial treatment of every topic the paper claims to address. The completeness warning that the manuscript ends mid-sentence further confirms this is not ready for publication in any form.\n\nThe reviewers are applying appropriate standards for a research venue in security, cryptography, and privacy. Even if this were evaluated as an industry report or survey paper, it would still fall short: surveys require systematic methodology, comprehensive citation coverage, and structured comparative analysis\u2014none of which are present here. The paper's breadth (prediction, trading, security, regulation, sustainability, education) is a liability rather than an asset, as it prevents meaningful depth on any single topic. Both reviewers correctly note that the most promising elements\u2014reflexivity in AI-driven markets, the AI attack/defense arms race\u2014are mentioned but never developed.\n\nAs this is Round 1 of 2, there is one revision opportunity remaining. However, the changes required are not incremental fixes but a fundamental reconceptualization of the paper's scope, contribution, and scholarly apparatus. The authors must narrow to a specific, defensible contribution; replace the entire citation base with domain-appropriate peer-reviewed literature; resolve all '[citation needed]' placeholders; complete the manuscript (it currently ends mid-sentence); and either provide original empirical work or, if pursuing a survey format, deliver structured technical comparisons with evaluation metrics. This is achievable in one round only if the authors are willing to essentially rewrite the paper with a focused scope.",
    "key_strengths": [
      "Clear, accessible writing with logical organizational structure that orients readers through the AI-cryptocurrency landscape",
      "Identification of reflexivity and algorithmic herding in AI-driven crypto markets as an important and underappreciated dynamic",
      "Recognition of the AI-powered attack vs. defense arms race in cryptocurrency security as a defining characteristic of the space"
    ],
    "key_weaknesses": [
      "No original contribution: no novel experiments, framework, taxonomy, empirical findings, or structured critical comparison\u2014the paper is a surface-level overview without research substance",
      "Critically inadequate citation base with multiple '[citation needed]' placeholders, heavy reliance on non-peer-reviewed sources, and complete omission of foundational literature (MEV/Flash Boys 2.0, AMM microstructure, FinBERT, crypto-specific RL, MiCA regulation)",
      "Manuscript is incomplete (ends mid-sentence) and attempts to cover too many topics (prediction, trading, security, regulation, sustainability, education) resulting in superficial treatment of all"
    ],
    "required_changes": [
      "Complete the manuscript\u2014it currently ends mid-sentence\u2014and narrow the scope to a single, well-defined contribution (e.g., a critical review of backtesting practices in crypto-AI papers, or an analysis of AI agents in MEV extraction, or a structured comparison of sentiment analysis methods for crypto markets)",
      "Replace all non-peer-reviewed sources with domain-specific academic literature, resolve every '[citation needed]' placeholder with actual references, and engage with foundational works: Daian et al. (2020) on MEV, Capponi & Jia (2021) on AMMs, Makarov & Schoar (2020) on crypto arbitrage, Cong et al. (2023) on wash trading, and relevant RL/transformer papers for financial time series",
      "Provide either original empirical results with proper methodology (datasets, metrics, train/test protocols, baselines) or, if pursuing a survey format, deliver structured comparison tables with reported performance metrics, evaluation protocols, datasets, prediction horizons, and critical assessment of methodological validity across cited studies"
    ],
    "recommendation": "This manuscript requires fundamental restructuring to be considered for publication. The authors should: (1) choose a narrow, specific topic and develop it with technical depth rather than surveying the entire AI-crypto landscape superficially; (2) build a proper scholarly foundation with peer-reviewed, domain-specific citations; (3) define and deliver a clear original contribution\u2014whether empirical, methodological, or a rigorous systematic review; and (4) complete the manuscript. Given the severity of the issues, acceptance after one more round is possible only if the revision represents a near-complete rewrite with focused scope and genuine scholarly rigor.",
    "round": 1,
    "overall_average": 3.7,
    "tokens": 4301
  },
  "author_response": "# Author Response - Round 1\n\n## Overview\n\nWe thank both reviewers for their thorough and constructive feedback. The reviews identify a consistent and critical issue: our manuscript attempts to survey a broad landscape (AI/ML applications across prediction, trading, security, regulation, and market microstructure) without sufficient technical depth, original contribution, or rigorous engagement with domain-specific literature. Both reviewers correctly identify that the manuscript reads as an extended overview or industry briefing rather than a focused research contribution, and they highlight specific, actionable deficiencies: missing citations to foundational peer-reviewed work, unsubstantiated claims lacking quantitative support, incomplete citations, and superficial treatment of complex technical topics.\n\nWe recognize the validity of these critiques. Rather than attempt to address all topics at greater depth\u2014which would only expand an already unfocused manuscript\u2014we have decided to fundamentally reconceptualize the work around a single, defensible contribution with technical rigor. Specifically, we will reframe the manuscript as a **critical methodological review of backtesting practices and evaluation protocols in AI/ML-for-crypto-trading research**, with particular emphasis on documenting common pitfalls (overfitting, look-ahead bias, data leakage, unrealistic assumptions about transaction costs and slippage) that lead to spectacular backtest results that fail in live trading. This narrower scope will allow us to (1) engage deeply with the technical substance of ML architectures and their evaluation, (2) provide a structured, evidence-based taxonomy of failure modes, and (3) offer actionable guidance for researchers and practitioners. We detail this strategy and our responses to specific concerns below.\n\n---\n\n## Response to Reviewer 1 (AI/ML for Financial Market Prediction and Algorithmic Trading)\n\n**Overall Assessment**: We acknowledge the reviewer's score of 3.7/10 and fully accept the core criticism: our manuscript lacks methodological rigor, original experiments, quantitative results, and substantive technical engagement with the ML architectures we discuss. The reviewer is correct that claims like \"hybrid CNN-LSTM models achieved superior performance\" are scientifically meaningless without specific metrics, datasets, validation protocols, and baselines. We also accept the assessment that our citation base is critically weak, with excessive reliance on industry sources and multiple unresolved '[citation needed]' placeholders that signal incomplete scholarship.\n\n### Major Points\n\n**1. Absence of Methodological Rigor and Quantitative Results**\n\n- **Our response**: We recognize this is the manuscript's most fundamental deficiency. We do not conduct original experiments, nor do we report actual performance metrics (Sharpe ratio, RMSE, directional accuracy, maximum drawdown, Calmar ratio), validation protocols (walk-forward, expanding window), or baselines. The reviewer is entirely correct that this renders all performance claims vacuous.\n\n- **Action taken**: Rather than add original experiments (which would require significant new work and is outside the scope of a short paper), we are reframing the manuscript as a **critical methodological review**. We will systematically examine backtesting practices in published crypto-AI papers, documenting the prevalence and severity of common evaluation failures. We will create a structured table comparing reported metrics, datasets, time periods, and validation methodologies across major published works (e.g., papers on LSTM for Bitcoin, CNN-LSTM hybrids, transformer-based approaches). For each method class, we will critically assess whether cited studies employ walk-forward validation, account for transaction costs and slippage, control for look-ahead bias, and address survivorship bias. This approach allows us to make rigorous claims about the state of the field without requiring original empirical work.\n\n**2. Weak Citation Base and Missing Foundational Literature**\n\n- **Our response**: The reviewer correctly identifies that our citations are insufficient and heavily weighted toward non-peer-reviewed sources. The specific missing references they cite\u2014Bao et al. (2017) on deep learning for stock prediction, FinBERT and crypto-specific sentiment models, Deng et al. (2016) and Jiang et al. (2017) on RL-for-trading, and literature on non-stationarity and regime-switching\u2014are indeed critical to any serious treatment of this topic. The '[citation needed]' placeholders are inappropriate for a research manuscript and indicate incomplete work.\n\n- **Action taken**: We will conduct a comprehensive literature review and replace all '[citation needed]' placeholders with peer-reviewed sources or remove unsupported claims. Specifically, we will:\n  - Add citations to Bao et al. (2017), Jiang et al. (2017), Deng et al. (2016), and other foundational RL-for-trading papers.\n  - Cite recent transformer architectures for financial time series: Temporal Fusion Transformers (Lim et al., 2021), Informer (Zhou et al., 2021), and their application to crypto.\n  - Include references to FinBERT (Huang et al., 2022) and domain-adapted LLMs for crypto sentiment analysis.\n  - Engage with the substantial literature on non-stationarity in crypto markets: regime-switching models, concept drift detection, and empirical evidence of market regime changes.\n  - Replace industry blog posts and Forbes articles with peer-reviewed equivalents where possible, or remove unsupported claims.\n  - Ensure all remaining citations are to archival peer-reviewed venues (journals, top-tier conferences) rather than arXiv preprints or industry sources, unless the latter are the only available source for a specific claim.\n\n**3. Lack of Original Contribution**\n\n- **Our response**: The reviewer is correct that the manuscript synthesizes existing work at a high level without adding a new framework, taxonomy, empirical finding, or critical comparison. The \"Future Predictions\" section is speculative and grounded in no quantitative analysis.\n\n- **Action taken**: We will redefine the manuscript's contribution as a **structured critical review of backtesting methodologies in crypto-AI research**. The specific contributions will be:\n  - A taxonomy of common evaluation failures in published crypto-AI papers, with documented examples from the literature.\n  - A structured comparison table of reported metrics, datasets, validation protocols, and known limitations across major method classes (LSTM, CNN-LSTM, Transformer, RL).\n  - Critical assessment of whether cited studies employ industry-standard practices (walk-forward validation, transaction cost modeling, slippage accounting, look-ahead bias detection).\n  - Evidence-based guidance for researchers on best practices for backtesting AI/ML trading systems in crypto markets.\n  - Discussion of the specific challenges of crypto markets that exacerbate evaluation pitfalls: high volatility, 24/7 trading, decentralized exchange fragmentation, and regulatory uncertainty.\n\nThis narrower scope allows us to make a genuine contribution to the field by documenting and analyzing a real problem\u2014the prevalence of overfitting and unrealistic backtests\u2014rather than attempting to survey an impossibly broad landscape.\n\n### Minor Points\n\nThe reviewer notes that our writing is generally clear and the discussion of reflexivity and algorithmic herding (citing Krafft et al.) is worthwhile. We will retain and expand this discussion, as it is one of the few original insights in the current manuscript. We will also acknowledge the organizational clarity while emphasizing that we are now reorganizing around a narrower thesis. The reviewer's suggestion to provide a \"structured comparison table with reported metrics, datasets, prediction horizons, and known limitations\" is exactly what we will implement as the core analytical contribution.\n\n---\n\n## Response to Reviewer 2 (Cryptocurrency Market Microstructure and Digital Asset Economics)\n\n**Overall Assessment**: We acknowledge the reviewer's score of 3.7/10 and accept their core assessment: the manuscript reads as a broad survey rather than a focused short paper with a clear contribution, and it lacks substantive engagement with cryptocurrency market microstructure\u2014the purported core topic. The reviewer is correct that we rely heavily on non-peer-reviewed sources while omitting the most relevant literature on DEX/CEX dynamics, MEV, on-chain order flow, and regulatory frameworks. The five consecutive '[citation needed]' markers in the regulatory section are particularly problematic and signal incomplete scholarship.\n\n### Major Points\n\n**1. Absence of Substantive Market Microstructure Analysis**\n\n- **Our response**: We acknowledge that our treatment of market microstructure is superficial. The single sentence on AMMs is inadequate; we do not discuss DEX vs. CEX dynamics, MEV extraction by AI agents, on-chain order flow, mempool dynamics, or AMM pricing mechanics (constant product functions, concentrated liquidity). The reviewer is correct that this represents a fundamental gap for a paper claiming to address market microstructure effects.\n\n- **Action taken**: Given the scope constraints of a short paper, we will **not** attempt to add comprehensive market microstructure analysis to our backtesting-focused revision. However, we recognize that MEV is the most critical intersection of AI and crypto market microstructure, and we will add a dedicated section discussing how AI agents interact with MEV extraction, frontrunning, and sandwich attacks. Specifically, we will:\n  - Cite Daian et al. (2020) \"Flash Boys 2.0\" and discuss empirical evidence of MEV extraction on Ethereum.\n  - Reference Capponi & Jia (2021) and Aoyagi (2020) on AMM microstructure and how AI agents optimize liquidity provision.\n  - Cite Makarov & Schoar (2020) on crypto arbitrage and price efficiency.\n  - Discuss how backtesting of AI trading systems must account for MEV extraction, sandwich attacks, and on-chain ordering dynamics\u2014factors that are often ignored in published backtests but critically impact live performance.\n  - Acknowledge that a comprehensive treatment of market microstructure is beyond the scope of a short paper and explicitly position our contribution as focused on backtesting methodology rather than market microstructure analysis per se.\n\n**2. Weak and Tangential Citation Base**\n\n- **Our response**: The reviewer correctly identifies that our citations are largely tangential (Indian stock market power laws, AI in education, AI in smart cities, AI in auditing) and that critical works in the crypto market microstructure field are entirely absent. The '[citation needed]' markers, particularly five consecutive ones in the regulatory section, are unacceptable for a research manuscript.\n\n- **Action taken**: We will replace all tangential citations with domain-specific literature. At minimum, we will cite:\n  - **MEV and frontrunning**: Daian et al. (2020), Weintraub et al. (2021), Kulkarni et al. (2022).\n  - **AMM microstructure**: Capponi & Jia (2021), Aoyagi (2020), Angeris et al. (2021).\n  - **Price efficiency and arbitrage**: Makarov & Schoar (2020), Barbon & Ranaldo (2021).\n  - **Wash trading detection**: Cong et al. (2023), Victor & Weintraub (2021).\n  - **Regulatory frameworks**: MiCA text, SEC enforcement orders (Binance, Coinbase), FATF guidance, and academic papers on crypto regulation (e.g., Houben & Snyers, 2020).\n  - **DeFi market dynamics**: Papers on liquidation mechanisms in Aave and Compound, AI-driven liquidation bot behavior, and systemic risk in DeFi lending.\n  \n  All '[citation needed]' markers will be resolved with actual peer-reviewed references or the claims will be removed.\n\n**3. Lack of Focus and Clear Contribution**\n\n- **Our response**: The reviewer correctly identifies that the current manuscript attempts to cover prediction, trading, security, regulation, sustainability, and education, resulting in superficial treatment of everything. This is an accurate diagnosis of the manuscript's fundamental structural problem.\n\n- **Action taken**: As noted in the Overview, we are reconceptualizing the manuscript around a single, focused contribution: **a critical methodological review of backtesting practices in AI/ML-for-crypto-trading research**. This allows us to:\n  - Maintain engagement with the prediction and trading aspects (which are central to the backtesting review).\n  - Incorporate discussion of MEV and market microstructure effects as **confounds that backtesting often fails to account for**.\n  - Treat security and fraud detection as **evaluation challenges** (e.g., detecting whether a model is robust to adversarial attacks on input data).\n  - Discuss regulation as a **constraint on backtesting assumptions** (e.g., transaction cost modeling must account for regulatory compliance costs).\n  - Explicitly remove or drastically curtail sections on sustainability and education, which are tangential to the core contribution.\n\nThis narrowing will allow us to achieve technical depth on a defensible contribution rather than breadth without substance.\n\n### Minor Points\n\nThe reviewer notes that our writing is clear and well-organized, and that we correctly flag the arms race between AI-powered attack and defense vectors in crypto security. We will retain these strengths while reorganizing the manuscript around the narrower contribution.\n\n---\n\n## Summary of Changes\n\n### Major Revisions (Planned)\n\n1. **Reconceptualize the manuscript as a critical methodological review** of backtesting practices in AI/ML-for-crypto-trading research, rather than a broad survey of AI applications in crypto.\n\n2. **Create a structured taxonomy of backtesting failures** with documented examples from published papers:\n   - Overfitting and model selection bias\n   - Look-ahead bias and data leakage\n   - Unrealistic transaction cost and slippage assumptions\n   - Insufficient walk-forward validation\n   - Survivorship bias in exchange/asset selection\n   - Failure to account for market impact and MEV extraction\n   - Inadequate baseline comparisons\n\n3. **Develop a structured comparison table** documenting reported metrics, datasets, time periods, validation protocols, and known limitations across major method classes (LSTM, CNN-LSTM, Transformer, RL, sentiment-based approaches).\n\n4. **Add a dedicated section on MEV and market microstructure confounds** in backtesting, explaining how AI agents interact with frontrunning, sandwich attacks, and on-chain ordering dynamics, and how published backtests often fail to account for these factors.\n\n5. **Conduct a comprehensive literature review** and replace all non-peer-reviewed sources with peer-reviewed equivalents where available. Specifically:\n   - Add citations to foundational papers: Bao et al. (2017), Jiang et al. (2017), Deng et al. (2016), Daian et al. (2020), Capponi & Jia (2021), Cong et al. (2023).\n   - Include recent transformer and LLM papers for financial prediction.\n   - Replace all '[citation needed]' placeholders with actual references or remove unsupported claims.\n\n6. **Remove or drastically curtail sections** on sustainability, education, and general regulatory frameworks that are tangential to the backtesting methodology focus.\n\n7. **Develop actionable guidance** for researchers and practitioners on best practices for backtesting AI/ML trading systems in crypto markets, grounded in the documented failures identified in the review.\n\n### Minor Revisions\n\n- Retain and expand the discussion of reflexivity and algorithmic herding (Krafft et al.) as one of the few original insights.\n- Clarify the distinction between CEX and DEX microstructure and how this affects backtesting assumptions.\n- Provide concrete examples of how common backtesting failures have led to spectacular published results that failed in live trading (with cited examples).\n- Acknowledge scope limitations: the paper is focused on backtesting methodology, not comprehensive market microstructure analysis or regulatory compliance, and position it accordingly.\n\n### Word Count and Scope\n\nThe revised manuscript will likely remain in the 2,500\u20133,500 word range, focused on a single, defensible contribution with sufficient technical depth and rigorous citations to meet research standards.\n\n---\n\n## Closing Remarks\n\nWe appreciate the detailed feedback from both reviewers. The core message\u2014that our manuscript lacks focus, rigor, and original contribution\u2014is clear and valid. Rather than attempt to address all feedback by adding more content, we have decided to fundamentally refocus the work around a narrower, more defensible contribution that we can develop with appropriate technical depth. We believe this approach better serves both the research community and the standards of a peer-reviewed venue. We look forward to resubmitting a substantially revised manuscript that addresses these fundamental concerns.",
  "manuscript_diff": {
    "words_added": -245,
    "previous_version": "v1",
    "current_version": "v2"
  },
  "threshold": 7.5,
  "passed": false,
  "timestamp": "2026-02-09T02:10:22.957664",
  "revised_word_count": 2438
}