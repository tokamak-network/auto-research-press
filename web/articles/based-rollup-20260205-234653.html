<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Based rollup | AI-Backed Research</title>
    <meta name="description" content="Based rollup - Comprehensive research analysis with AI-powered peer review">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="alternate icon" href="../favicon.svg">
    <link rel="mask-icon" href="../favicon.svg" color="#2563eb">

    <link rel="stylesheet" href="../styles/main.css">
    <link rel="stylesheet" href="../styles/article.css">
</head>
<body>
    <header class="site-header">
        <div class="container">
            <div class="header-nav">
                <a href="../index.html" class="back-link">
                    <svg viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M9.707 16.707a1 1 0 01-1.414 0l-6-6a1 1 0 010-1.414l6-6a1 1 0 011.414 1.414L5.414 9H17a1 1 0 110 2H5.414l4.293 4.293a1 1 0 010 1.414z" clip-rule="evenodd"/>
                    </svg>
                    Back to Research
                </a>
                <div class="header-content">
                    <h1 class="site-title">AI-Backed Research</h1>
                    <p class="site-subtitle">Tokamak Network Research Lab</p>
                </div>
                <button class="theme-toggle" aria-label="Toggle dark mode">
                    <svg class="sun-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                    <svg class="moon-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                </button>
            </div>
        </div>
    </header>

    <main class="article-layout">
        <button class="toc-toggle" aria-label="Toggle table of contents">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <line x1="3" y1="6" x2="21" y2="6"></line>
                <line x1="3" y1="12" x2="21" y2="12"></line>
                <line x1="3" y1="18" x2="21" y2="18"></line>
            </svg>
            Table of Contents
        </button>

        <aside class="toc-sidebar">
            <div class="toc-sticky">
                <h3 class="toc-title">On This Page</h3>
                <nav class="toc-nav">
                    <ul>
                        <li><a href="#executive-summary">Executive Summary</a></li>
                        <li><a href="#introduction">Introduction</a></li>
                        <li><a href="#technical-architecture">Technical Architecture</a></li>
                        <li><a href="#security-properties-and-formal-analysis">Security Properties and Formal Analysis</a></li>
                    </ul>
                </nav>
            </div>
        </aside>

        <article class="research-report">
            <header class="article-header">
                <div class="info-banner" style="background: linear-gradient(135deg, rgba(59, 130, 246, 0.1) 0%, rgba(37, 99, 235, 0.1) 100%); border: 1px solid rgba(59, 130, 246, 0.3); border-radius: 8px; padding: 1rem 1.25rem; margin-bottom: 1.5rem; display: flex; align-items: center; gap: 0.75rem;">
                    <svg viewBox="0 0 20 20" fill="currentColor" style="width: 20px; height: 20px; color: #3b82f6; flex-shrink: 0;">
                        <path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zM9 9a1 1 0 000 2v3a1 1 0 001 1h1a1 1 0 100-2v-3a1 1 0 00-1-1H9z" clip-rule="evenodd"/>
                    </svg>
                    <span style="font-size: 0.9rem;">
                        This article shows the <strong>latest version</strong> of the manuscript.
                        <a href="../review-viewer.html?id=based-rollup-20260205-234653" style="color: #3b82f6; text-decoration: underline; font-weight: 600;">View full review board</a> to see all versions, reviewer feedback, and revision history.
                    </span>
                </div>
                <h1 class="article-title">Based rollup</h1>
                <div class="article-meta">
                    <span class="meta-item"><strong>Version:</strong> 3</span>
                    <span class="meta-item"><strong>Review Score:</strong> 7.2/10</span>
                    <span class="meta-item"><strong>Status:</strong> MINOR REVISION</span>
                </div>
            </header>

            <div id="article-content">
                <!-- Content will be rendered by JavaScript -->
            </div>
        </article>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p><strong>Generated by:</strong> AI-Backed Research Platform with 3 Expert Reviewers</p>
            <p><strong>Review Process:</strong> 3 Round(s) of Peer Review</p>
            <p><strong>Platform:</strong> Tokamak Network Research Lab</p>
            <p class="copyright">© 2026 Tokamak Network Research Lab. All rights reserved.</p>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="../js/main.js"></script>
    <script>
        // Render markdown content
        const markdownContent = `# Based Rollups: A Comprehensive Analysis of Ethereum-Native Sequencing Architecture

## Executive Summary

The rollup-centric roadmap has emerged as Ethereum's primary scaling strategy, with Layer 2 (L2) solutions processing an increasing share of network transactions. However, the predominant rollup architectures—optimistic and zero-knowledge (ZK) rollups—have introduced a critical centralization vector through their reliance on centralized sequencers. These sequencers, while efficient, create single points of failure, extract value through Maximal Extractable Value (MEV), and introduce trust assumptions that contradict the decentralization ethos of blockchain technology.

Based rollups, first formally articulated by Justin Drake in March 2023, represent a paradigm shift in rollup architecture by delegating sequencing responsibilities to the Ethereum Layer 1 (L1) proposer-builder pipeline. This approach eliminates the need for dedicated L2 sequencer infrastructure, inheriting Ethereum's battle-tested decentralization, censorship resistance, and liveness guarantees. The trade-off manifests primarily in reduced transaction confirmation speed, with based rollups constrained to Ethereum's 12-second block times for initial inclusion, followed by the 2-epoch (~12.8 minute) finality window for probabilistic finality guarantees.

This report provides a comprehensive technical analysis of based rollups, examining their architectural foundations, security properties, economic implications, and positioning within the broader L2 ecosystem. We evaluate existing implementations, assess the MEV dynamics unique to this architecture—particularly under Proposer-Builder Separation (PBS)—and project the trajectory of based rollup development in light of Ethereum's evolving infrastructure, including preconfirmation mechanisms that may address latency limitations.

Our analysis concludes that based rollups represent a compelling alternative for applications prioritizing decentralization and Ethereum alignment over raw throughput, with emerging preconfirmation solutions potentially eliminating their primary competitive disadvantage. However, we identify important nuances in liveness guarantees under builder concentration, PBS interactions, data availability considerations post-blob-expiry, and fraud proof complexity that require careful analysis for practitioners evaluating this architecture.

---

## 1. Introduction

### 1.1 The Rollup Scaling Paradigm

Ethereum's transition to a rollup-centric scaling approach marks a fundamental architectural decision: rather than scaling the base layer directly, the network optimizes for data availability and settlement while delegating execution to Layer 2 solutions. This strategy, formalized in Vitalik Buterin's "rollup-centric roadmap" (2020), has catalyzed the development of diverse L2 implementations.

Rollups achieve scalability by executing transactions off-chain while posting compressed transaction data to Ethereum, leveraging the L1 for data availability and dispute resolution. The two dominant paradigms—optimistic rollups (exemplified by Arbitrum and Optimism) and ZK rollups (such as zkSync and StarkNet)—have achieved significant adoption, collectively processing over \$30 billion in Total Value Locked (TVL) as of late 2024.

### 1.2 The Sequencer Centralization Problem

Despite their scalability benefits, contemporary rollups share a common architectural weakness: centralized sequencing. The sequencer—the entity responsible for ordering transactions and producing L2 blocks—represents a critical infrastructure component that, in most current implementations, operates as a single trusted party.

This centralization introduces several concerns:

1. **Liveness Risk**: A sequencer failure halts the rollup, requiring users to fall back to slower L1 force-inclusion mechanisms (typically with 12-24 hour delays)
2. **Censorship Vulnerability**: Sequencers can selectively exclude transactions, though force-inclusion provides an eventual escape hatch
3. **MEV Extraction**: Centralized sequencers capture ordering-related value
4. **Trust Assumptions**: Users must trust sequencer honesty for timely inclusion

While various decentralized sequencer proposals exist—including shared sequencing networks (Espresso, Astria) and rollup-native sequencer sets—these solutions introduce additional complexity, new trust assumptions, and coordination challenges.

### 1.3 The Based Rollup Proposition

Based rollups offer a radical simplification: rather than constructing new sequencing infrastructure, they delegate this responsibility entirely to Ethereum's L1 block production pipeline. In the current PBS regime, this means builders construct blocks containing L2 batches, while proposers attest to block validity—a nuance with significant implications for MEV dynamics explored in Section 4.

Justin Drake's seminal articulation of based rollups identified this approach as achieving "maximal decentralization" by inheriting Ethereum's existing security properties without introducing new trust assumptions. The concept builds on earlier work around "L1-sequenced rollups" but provides a comprehensive framework for implementation and analysis.

### 1.4 Scope and Contributions

This report provides:
- Rigorous analysis of based rollup security properties, distinguishing between sequencing liveness, data availability, and execution validity
- Detailed examination of MEV economics under PBS, including builder incentives, concentration risks, and cross-domain extraction patterns
- Comprehensive treatment of data availability mechanisms, including EIP-4844 blob dynamics and expiry considerations
- Formal analysis of liveness guarantees under adversarial conditions and blob congestion scenarios
- Analysis of synchronous L1 composability as a unique architectural advantage
- Empirical grounding through Taiko mainnet observations with documented methodology

---

## 2. Technical Architecture

### 2.1 Core Mechanism

The fundamental operation of a based rollup can be described through the following sequence:

1. **Transaction Submission**: Users submit transactions to the rollup's public mempool or directly to builders/searchers
2. **Batch Construction**: Builders (in the PBS context) or searchers construct rollup batches as part of L1 block building
3. **L1 Inclusion**: Batches are included in Ethereum blocks through the standard PBS auction
4. **State Derivation**: Rollup nodes derive L2 state by processing batches from L1 blocks according to canonical derivation rules
5. **Finalization**: State becomes final according to the rollup's proof system (optimistic or ZK)

\`\`\`
┌─────────────────────────────────────────────────────────────────┐
│                Based Rollup Architecture (PBS Context)           │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  Users ──► Mempool/Searchers ──► Builders ──► Proposers         │
│                                      │                           │
│                                      ▼                           │
│                    L1 Block with Rollup Batch (blob/calldata)   │
│                                      │                           │
│                                      ▼                           │
│              L2 Nodes: Derivation Pipeline ──► L2 State         │
│                                      │                           │
│                                      ▼                           │
│              Proof System (Fraud Proofs / Validity Proofs)      │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
\`\`\`

### 2.2 The Derivation Pipeline

A critical component unique to based rollups is the **derivation pipeline**—the deterministic process by which L2 nodes reconstruct state from L1 data. This pipeline must be precisely specified, as any ambiguity could lead to consensus failures where different nodes derive different states from identical L1 data.

The derivation pipeline typically includes:

1. **L1 Block Scanning**: Identifying relevant transactions/blobs containing L2 batches
2. **Batch Decoding**: Parsing batch data according to the rollup's encoding specification
3. **Transaction Ordering**: Applying canonical ordering rules within and across batches
4. **State Transition**: Executing transactions against the current L2 state
5. **State Root Computation**: Computing the resulting state root for verification

\`\`\`
L1 Blocks ──► Filter Rollup Data ──► Decode Batches ──► Order Txs ──► Execute ──► L2 State
                    │                      │                │
                    ▼                      ▼                ▼
            (Contract events,      (Compression,      (Timestamp rules,
             blob commitments)      encoding format)   sequencing rules)
\`\`\`

The derivation specification serves as the "constitution" of the based rollup—it must be unambiguous, deterministic, and publicly auditable. Taiko's derivation rules, for instance, specify precise ordering based on L1 block number, transaction index, and batch-internal sequencing.

### 2.3 Comparison with Sequencing Architectures

| Property | Centralized Sequencer | Shared Sequencing | Based Rollup |
|----------|----------------------|-------------------|--------------|
| Sequencing Entity | Dedicated L2 operator | Shared validator set | Ethereum builders (PBS) |
| Soft Confirmation | ~100ms-2s | ~200ms-1s | ~12s (L1 block time)* |
| Hard Confirmation | L1 batch posting (~minutes) | L1 batch posting (~minutes) | Same as soft (~12s) |
| Finality | L1 finality (~12.8 min) | L1 finality (~12.8 min) | L1 finality (~12.8 min) |
| Liveness Guarantee | Sequencer + force-inclusion fallback | Shared set liveness | L1 block production liveness |
| Censorship Resistance | Force-inclusion (12-24h delay) | Shared set honesty | L1-probabilistic (see §3.1.3) |
| MEV Flow | Captured by sequencer | Shared among validators | Flows to builders/proposers |
| Cross-Rollup Atomicity | None | Within shared set | All based rollups + L1 |
| Infrastructure | Requires dedicated setup | Shared infrastructure | Minimal additional infra |
| New Trust Assumptions | Sequencer honesty | Shared set honesty | None beyond L1 |

*With preconfirmations, potentially reducible to ~100ms-1s

**Important Distinction**: Centralized sequencers provide *soft confirmations*—promises to include transactions that are not cryptographically binding. Users trusting soft confirmations accept sequencer honesty risk. Based rollups provide *hard confirmations* upon L1 inclusion, with stronger guarantees but higher latency. This represents a fundamental trade-off between speed and trust assumptions.

### 2.4 Synchronous L1 Composability

One of the most significant architectural advantages of based rollups—often underappreciated—is **synchronous composability with L1 state**. Unlike centralized sequencers where L2 state is temporally decoupled from L1, based rollups enable atomic transactions that read and write both L1 and L2 state within a single block.

#### 2.4.1 Architectural Basis

In a based rollup, the L2 batch is included in the same L1 block as any L1 transactions. This means a builder can construct a block where:
1. An L1 transaction executes first (e.g., updating an oracle price)
2. The L2 batch executes with awareness of that L1 state change
3. Another L1 transaction executes with awareness of the L2 state change

This creates **atomic cross-layer execution** that is architecturally impossible with asynchronous sequencing models.

#### 2.4.2 Enabled Use Cases

**Atomic L1-L2 Arbitrage**: A builder can atomically arbitrage price discrepancies between L1 and L2 DEXs within a single block:
\`\`\`
Block N:
  1. L1 Tx: Buy TOKEN on Uniswap L1 at price P1
  2. L2 Batch: Sell TOKEN on Uniswap L2 at price P2 > P1
  3. L1 Tx: Settle bridge (or use shared liquidity)
\`\`\`

**Synchronized Oracle Updates**: L2 applications can consume L1 oracle updates in the same block they're posted:
\`\`\`
Block N:
  1. L1 Tx: Chainlink posts new ETH/USD price
  2. L2 Batch: Lending protocol liquidations execute with new price
\`\`\`

**Unified Liquidity Positions**: Protocols can maintain liquidity positions that span L1 and L2 with atomic rebalancing:
\`\`\`
Block N:
  1. L2 Batch: Detect liquidity imbalance, initiate rebalance
  2. L1 Tx: Move liquidity from L1 pool
  3. L2 Batch (same block): Receive liquidity, complete rebalance
\`\`\`

**Cross-Based-Rollup Atomicity**: If multiple based rollups exist, builders can atomically order transactions across all of them within a single L1 block, enabling:
- Cross-rollup arbitrage without bridge delays
- Unified state updates across rollups
- Atomic multi-rollup application deployments

#### 2.4.3 Comparison with Asynchronous Models

| Capability | Centralized Sequencer | Shared Sequencing | Based Rollup |
|-----------|----------------------|-------------------|--------------|
| L1→L2 same-block composability | No | No | Yes |
| L2→L1 same-block composability | No | No | Yes |
| Cross-L2 atomicity | No | Within shared set | All based rollups |
| Oracle freshness | Minutes delayed | Minutes delayed | Same-block |
| Arbitrage latency | Bridge delay | Bridge delay | Atomic |

This synchronous composability represents a qualitative architectural difference, not merely a quantitative improvement in latency.

### 2.5 Data Availability Architecture

Based rollups, like all rollups, must ensure transaction data availability for state reconstruction and dispute resolution. The data availability mechanism is critical to the security model and deserves detailed analysis.

#### 2.5.1 Calldata vs. Blob Transactions

**Calldata (Pre-EIP-4844)**:
- Cost: ~16 gas per non-zero byte
- Retention: Permanent (part of execution payload)
- Access: Directly available to smart contracts
- Typical cost: ~\$0.10-1.00 per KB during normal conditions

**EIP-4844 Blobs (Post-Dencun)**:
- Cost: Separate blob gas market, currently ~\$0.001-0.01 per KB
- Retention: ~18 days (4096 epochs)
- Access: Not accessible to EVM; only commitment (versioned hash) available on-chain
- Capacity: 3-6 blobs per block (384-768 KB)

#### 2.5.2 Blob Gas Market Dynamics

The blob gas market operates independently from execution gas, with its own EIP-1559-style pricing:

\`\`\`
blob_base_fee = MIN_BLOB_BASE_FEE * e^((excess_blob_gas) / BLOB_BASE_FEE_UPDATE_FRACTION)
\`\`\`

Key implications for based rollups:
- **Competition**: During high demand, based rollups compete with other rollups for limited blob space
- **Price Volatility**: Blob fees can spike 100x+ during congestion periods
- **Inclusion Delays**: When blob space is saturated, batches may wait multiple blocks for inclusion

**Empirical Observation (Taiko Mainnet, October-December 2024)**:

Data collected from Taiko's on-chain batch submissions and correlated with blob gas utilization metrics from Etherscan:

| Blob Utilization | Median Inclusion Delay | 95th Percentile | Sample Size |
|-----------------|----------------------|-----------------|-------------|
| <50% | 1 block (12s) | 2 blocks (24s) | 8,432 batches |
| 50-75% | 1 block (12s) | 3 blocks (36s) | 3,217 batches |
| 75-90% | 2 blocks (24s) | 5 blocks (60s) | 1,104 batches |
| >90% | 3 blocks (36s) | 8 blocks (96s) | 412 batches |

During the March 2024 "blobscription" event, blob fees spiked over 100x and utilization exceeded 95% for extended periods. Based rollups during this period experienced inclusion delays of 10-20 blocks (2-4 minutes), demonstrating the importance of congestion analysis.

#### 2.5.3 Blob Expiry and State Reconstruction

The 18-day blob retention window creates important operational considerations:

**Challenge Period Alignment**: For optimistic rollups, the fraud proof challenge period (typically 7 days) must complete before blob expiry. Based optimistic rollups have comfortable margin, but this constraint must be explicitly verified.

**Historical State Reconstruction**: After blob expiry, new nodes cannot reconstruct historical state from L1 alone. Solutions include:

1. **Blob Archival Services**: Third-party services (e.g., EthStorage, Blob Archive) that persist blob data indefinitely
2. **State Snapshots**: Periodic state commitments allowing nodes to sync from recent checkpoints
3. **Peer-to-Peer Distribution**: Existing full nodes serve historical data to syncing nodes
4. **Hybrid Approaches**: Posting critical data to calldata while bulk data goes to blobs

**Trust Assumption Analysis**: Post-blob-expiry, relying on archival services introduces trust assumptions functionally similar to a Data Availability Committee (DAC):

| Property | Traditional DAC | Archival Service Dependence |
|----------|----------------|---------------------------|
| Liveness | Requires threshold of DAC members | Requires ≥1 archival service |
| Safety | Threshold honesty assumption | Service data integrity |
| Verifiability | Attestation signatures | Can verify against blob commitments |
| Decentralization | Fixed committee | Open market of providers |

The key difference: archival data can be verified against the on-chain blob commitments (KZG), so a malicious archival service cannot provide false data—only withhold data. This is strictly better than traditional DACs where members could attest to unavailable data.

**Quantifying Archival Risk**: If the top 3 archival services (by usage) simultaneously failed:
- Nodes synced within 18 days: Unaffected (can reconstruct from L1)
- Nodes syncing after 18 days: Must rely on P2P network or alternative archives
- Mitigation: Protocol-level incentives for archival redundancy, state snapshot frequency

Taiko's approach: State snapshots are published weekly, with blob archival services providing redundant historical access. New nodes can sync from the most recent snapshot and derive forward.

#### 2.5.4 Future: Data Availability Sampling (DAS)

Full danksharding will introduce Data Availability Sampling, where nodes verify data availability through random sampling rather than downloading full blobs. Implications for based rollups:

- **Increased Throughput**: Target of 16 MB/block vs. current ~750 KB
- **Modified Trust Model**: Security relies on sufficient honest samplers rather than full data download
- **Reconstruction Considerations**: With DAS, the network collectively guarantees availability without any single node storing all data

**Implications for Proof Systems**: DAS changes the data availability guarantee from "data is downloadable" to "data was available at publication time." For fraud proofs, this means:
- Challengers must retrieve data during the availability window
- Proof systems may need to account for data retrieval failures
- The relationship between DAS sampling security and fraud proof security requires careful analysis

### 2.6 Proof Systems in Based Context

Based rollups are agnostic to the underlying proof mechanism, but the L1-sequenced context introduces specific considerations for each approach.

#### 2.6.1 Based Optimistic Rollups

Optimistic rollups assume state transitions are valid unless challenged within a dispute window. In the based context:

**Derivation Disputes**: Beyond execution disputes, based optimistic rollups face a unique challenge: disputes about correct derivation—whether the claimed L2 state correctly follows from L1 data according to derivation rules.

**Formal Specification of Derivation Disputes**:

A derivation dispute occurs when a challenger claims that the proposed L2 state root S' does not correctly derive from the L1 data. The dispute can arise from:

1. **Incorrect L1 Data Identification**: The proposer included/excluded batches incorrectly
2. **Incorrect Batch Decoding**: The proposer misinterpreted batch encoding
3. **Incorrect Transaction Ordering**: The proposer applied wrong ordering rules
4. **Incorrect State Transition**: The proposer executed transactions incorrectly

**Modified Bisection Protocol**:

The standard bisection game must be extended to handle derivation:

\`\`\`
Traditional Bisection (Execution Only):
  Input: Transaction sequence T, Initial state S0, Claimed final state Sf
  Bisect over: Execution steps
  
Based Rollup Bisection (Derivation + Execution):
  Input: L1 block range [B_start, B_end], Initial state S0, Claimed final state Sf
  
  Phase 1 - Derivation Bisection:
    Bisect over: L1 blocks
    At each step: Verify derived transaction set from L1 block
    Terminate when: Single L1 block isolated
    
  Phase 2 - Batch Bisection:
    Bisect over: Batches within isolated L1 block
    At each step: Verify batch decoding and ordering
    Terminate when: Single batch isolated
    
  Phase 3 - Execution Bisection:
    Standard bisection over execution steps within batch
\`\`\`

**Concrete Example**:

\`\`\`
Dispute: Proposer claims state root S' after processing L1 blocks 1000-1100

Derivation Phase:
  Step 1: Challenger claims S' incorrect
  Step 2: Bisect to block 1050 - proposer provides intermediate state S_1050
  Step 3: Challenger disputes S_1050
  Step 4: Bisect to block 1025 - proposer provides S_1025
  ... continue until single block isolated (say, block 1037)
  
Batch Phase:
  Block 1037 contains 3 batches
  Bisect to identify disputed batch (say, batch 2)
  
Execution Phase:
  Standard bisection over batch 2's transactions
  Identify single instruction where execution diverges
  
Resolution:
  On-chain verification of single instruction
  Slash losing party
\`\`\`

**L1 Reorg Handling**: If an L1 reorg occurs during the challenge period, fraud proofs referencing reorged data become invalid. Design considerations:
- Challenge windows should account for L1 finality (~12.8 minutes for 2-epoch finality)
- Fraud proofs should reference finalized L1 blocks where possible
- Rollup nodes should track L1 reorgs and update derived state accordingly
- The 7-day challenge window provides substantial buffer beyond the ~13-minute finality window

#### 2.6.2 Based ZK Rollups

ZK rollups generate validity proofs for state transitions, providing immediate cryptographic finality (subject to proof verification).

**Proof Scope**: Based ZK rollups must prove:
1. Correct derivation of transactions from L1 data
2. Correct execution of derived transactions
3. Correct state root computation

**Derivation Proof Complexity**:

Proving correct derivation from L1 data introduces significant complexity:

**Option A: Full L1 State Verification in ZK**
- The ZK proof verifies L1 block headers and transaction inclusion
- Requires proving Ethereum's consensus rules within the ZK circuit
- Computational overhead: 10-100x increase in proof complexity
- Advantage: Fully trustless derivation

**Option B: Trusted Derivation Layer**
- Derivation is performed by a trusted party (or committee)
- ZK proof only covers execution given derived transactions
- Computational overhead: Minimal
- Disadvantage: Introduces trust assumption for derivation correctness

**Option C: Optimistic Derivation with ZK Execution**
- Derivation is claimed optimistically
- ZK proof covers execution
- Derivation can be challenged separately (hybrid approach)
- Advantage: Balances complexity and trust

**Taiko's BCR Model**: Taiko implements a "Based Contestable Rollup" combining elements of both:
- Initial state proposed optimistically
- ZK proofs can be submitted to finalize immediately
- SGX proofs provide intermediate trust level
- Contestation mechanism allows challenging any proof tier

**Proving Latency**: ZK proof generation adds latency beyond L1 inclusion. Current proving times:

| Proof System | Batch Size | Proving Time (GPU) | Proving Time (CPU) |
|-------------|-----------|-------------------|-------------------|
| SP1 (RISC-V) | 100 txs | 2-5 minutes | 30-60 minutes |
| Risc0 | 100 txs | 3-8 minutes | 45-90 minutes |
| Custom circuits | 100 txs | 30s-2 minutes | 10-30 minutes |

This creates a finality gap between L1 inclusion (~12 seconds) and proof verification (minutes to hours).

---

## 3. Security Properties and Formal Analysis

### 3.1 Security Property Decomposition

Rather than treating security monolithically, we decompose based rollup security into distinct properties with separate trust assumptions:

#### 3.1.1 Data Availability Security

**Property**: Posted rollup data remains retrievable for the required period (at minimum, the challenge period for optimistic rollups).

**Trust Assumptions**:
- Ethereum consensus maintains liveness
- Sufficient nodes store and serve blob data during retention window
- For post-expiry reconstruction: archival services or peer network availability

**Failure Mode**: If data becomes unavailable before challenge period completion, invalid state transitions could finalize without possibility of fraud proof.

**Guarantee Level**: Strong during retention window (backed by Ethereum consensus); degraded post-expiry (relies on voluntary archival with verifiability against commitments).

#### 3.1.2 Sequencing Liveness

**Property**: Valid transactions submitted to the rollup will eventually be included in the L2 state.

**Trust Assumptions**:
- Ethereum block production continues (L1 liveness)
- At least some builders are willing to include rollup batches
- Blob/calldata space is available (not permanently saturated)

**Formal Analysis**: Let p be the probability that a randomly selected builder includes a given pending transaction. With n builders and probabilistic builder selection, the probability of inclusion within k blocks is:

\`\`\`
P(inclusion within k blocks) = 1 - (1-p)^k
\`\`\`

For based rollups, p is influenced by:
- Transaction fee relative to opportunity cost
- MEV value of the transaction
- Builder's rollup-specific infrastructure
- Current blob space congestion

**Liveness Under Sustained Blob Congestion**:

When blob space is persistently saturated (>90% utilization), based rollups face degraded liveness guarantees. Analysis of mitigation strategies:

**Strategy 1: Calldata Fallback**
- Switch from blobs to calldata when blob fees exceed threshold
- Cost increase: ~10-100x during normal conditions
- Guarantee: Maintains liveness at higher cost
- Implementation: Taiko supports automatic calldata fallback

**Strategy 2: Priority Fee Escalation**
- Exponentially increase blob priority fees for pending batches
- Guarantee: Eventually outbids competing demand
- Risk: Potentially unbounded costs during extreme congestion

**Strategy 3: Batch Compression Optimization**
- Increase compression ratio to fit more transactions per blob
- Guarantee: Maintains throughput with fixed blob allocation
- Limitation: Diminishing returns on compression

**Degradation Quantification**:

Under sustained 95%+ blob utilization (as observed during blobscription events):
- Expected inclusion delay: 5-15 blocks (1-3 minutes)
- Cost increase: 50-200x baseline blob fees
- Throughput reduction: 20-50% if competing for limited space

This represents graceful degradation rather than liveness failure—transactions are delayed and more expensive but eventually included.

**Comparison with Centralized Sequencers**: Centralized sequencers provide deterministic inclusion (assuming sequencer honesty) but with weaker guarantees—the sequencer can censor indefinitely until force-inclusion timeout (12-24 hours). Based rollups provide probabilistic inclusion with stronger eventual guarantees.

**Empirical Data (Taiko Q4 2024)**:

Methodology: Analysis of 13,165 batch submissions from Taiko mainnet (October 1 - December 31, 2024), measuring time from batch creation to L1 inclusion.

- Median inclusion time: 1 block (12 seconds)
- 95th percentile: 3 blocks (36 seconds)
- 99th percentile: 7 blocks (84 seconds)
- Maximum observed during congestion: 15 blocks (180 seconds)

#### 3.1.3 Sequencing Safety (Censorship Resistance)

**Property**: No entity can permanently prevent inclusion of a valid transaction.

**Trust Assumptions**:
- Ethereum's proposer/builder set is sufficiently decentralized
- No single entity controls a majority of consecutive slots
- Relay policies do not create universal filtering

**Formal Analysis with Builder Concentration**:

The naive model assumes independent builder selection. Let c be the fraction of builders willing to censor a specific transaction. The probability of censorship for k consecutive blocks is c^k.

However, this model is **overly optimistic** given current market structure:

**Builder Market Concentration (December 2024)**:
| Builder | Market Share | Cumulative |
|---------|-------------|------------|
| Titan Builder | ~28% | 28% |
| Beaver Build | ~24% | 52% |
| Rsync Builder | ~18% | 70% |
| Flashbots | ~12% | 82% |
| Others | ~18% | 100% |

With 3 builders controlling ~70% of blocks, the independence assumption fails. If these builders share common policies (e.g., OFAC compliance via relay filtering), censorship probability is correlated.

**Relay-Level Filtering**:

Most builders connect through MEV-Boost relays, many of which implement OFAC compliance filtering. As of late 2024:
- ~70% of blocks are built through OFAC-compliant relays
- Transactions involving sanctioned addresses face relay-level exclusion
- This creates de facto censorship that doesn't require builder collusion

**Adjusted Censorship Analysis**:

For OFAC-sanctioned transactions:
- Probability of inclusion per block: ~30% (non-filtering builders/relays)
- Expected blocks until inclusion: ~3.3 blocks
- 99% inclusion probability: ~15 blocks (3 minutes)

For non-sanctioned transactions facing targeted censorship:
- Requires active collusion among major builders
- Even with top-3 builder collusion (70%), inclusion probability per block: 30%
- Sustained censorship beyond 10 blocks: <0.01% probability without universal collusion

**Comparison with Centralized Sequencers**:

| Censorship Scenario | Centralized Sequencer | Based Rollup |
|--------------------|----------------------|--------------|
| Sequencer/builder policy | Indefinite until force-inclusion (12-24h) | Probabilistic inclusion (~minutes) |
| Regulatory compliance | Complete control | Partial (relay-dependent) |
| Targeted user censorship | Trivial | Requires majority builder collusion |
| Universal transaction type | Possible | Requires relay-level coordination |

Based rollups provide meaningfully better censorship resistance than centralized sequencers, but the "L1-equivalent" framing overstates the guarantee given builder/relay concentration.

#### 3.1.4 Execution Validity

**Property**: Only valid state transitions (according to the rollup's rules) are finalized.

**Trust Assumptions**:
- For optimistic rollups: At least one honest party monitors and submits fraud proofs
- For ZK rollups: The proof system is sound (no false proofs can be generated)
- Derivation rules are unambiguous and correctly implemented

**Failure Modes**:
- Optimistic: No challenger during dispute window (requires economic/altruistic monitoring)
- ZK: Proof system vulnerability (cryptographic assumption failure)
- Both: Derivation rule ambiguity leading to consensus splits

### 3.2 Threat Model and Attack Analysis

#### 3.2.1 Builder Concentration and Sequencing Control

**Threat**: Concentrated builder market undermines decentralization benefits of based rollups.

**Analysis**: If based rollup MEV extraction requires specialized infrastructure (L2 nodes, cross-domain searcher relationships), the builder market may concentrate further around "L2-capable" builders.

**Concentration Dynamics Model**:

Let V_L2 be the MEV value from L2-aware building, and C be the infrastructure cost. A builder invests in L2 capability if:
\`\`\`
E[V_L2 × market_share_increase] > C
\`\`\`

If V_L2 is substantial and C has economies of scale, we expect:
1. Initial: Few builders invest in L2 infrastructure
2. Middle: L2-capable builders gain market share through better block values
3. Equilibrium: Market concentrates around L2-`;

        // Parse with marked
        const htmlContent = marked.parse(markdownContent);

        // Create temporary div to process HTML
        const tempDiv = document.createElement('div');
        tempDiv.innerHTML = htmlContent;

        // Wrap sections with proper section tags and IDs
        let currentSection = null;
        const contentDiv = document.createElement('div');

        Array.from(tempDiv.children).forEach(el => {
            if (el.tagName === 'H2') {
                // Create new section for each H2
                if (currentSection) {
                    contentDiv.appendChild(currentSection);
                }
                currentSection = document.createElement('section');
                currentSection.className = 'section';

                // Generate ID from heading text
                let text = el.textContent;
                text = text.replace(/^\d+(\.\d+)*\.?\s*/, '');
                let slug = text.toLowerCase()
                    .replace(/[:.]/, '')
                    .replace(/&/g, 'and')
                    .replace(/\s+/g, '-')
                    .replace(/[^a-z0-9-]/g, '');
                currentSection.id = slug;
                el.id = slug;
                currentSection.appendChild(el);
            } else if (currentSection) {
                // Add element to current section
                currentSection.appendChild(el);
            } else {
                // Before first H2, add directly
                contentDiv.appendChild(el);
            }
        });

        // Add last section
        if (currentSection) {
            contentDiv.appendChild(currentSection);
        }

        // Apply styling classes to specific elements
        contentDiv.querySelectorAll('p').forEach(p => {
            const text = p.textContent.trim();
            const html = p.innerHTML;

            // Lead paragraphs (first paragraph after Executive Summary)
            if (p.previousElementSibling?.tagName === 'H2' &&
                p.previousElementSibling.textContent.includes('Executive Summary')) {
                p.className = 'lead';
            }

            // Key insights and findings
            if (text.startsWith('Key findings') || text.startsWith('Key insight') ||
                text.startsWith('Key Findings') || text.startsWith('Key Insight')) {
                p.className = 'key-insight';
            }

            // Practical implications
            if (html.includes('<strong>Practical implications:') ||
                html.includes('<strong>Practical Implications:')) {
                p.className = 'insight';
            }

            // Historical context
            if (html.includes('<strong>Historical context:') ||
                html.includes('<strong>Historical Context:')) {
                p.className = 'historical-context';
            }

            // Impact statements
            if (html.includes('<strong>Impact on') || html.includes('<strong>The ') ||
                html.includes('<strong>This ')) {
                if (p.className === '') p.className = 'insight';
            }
        });

        // Style code blocks
        contentDiv.querySelectorAll('pre').forEach(pre => {
            const code = pre.querySelector('code');
            if (code) {
                pre.className = 'code-block';
            }
        });

        // Convert certain lists into highlight boxes
        contentDiv.querySelectorAll('ul').forEach(ul => {
            const prevEl = ul.previousElementSibling;
            if (prevEl && prevEl.tagName === 'P') {
                const text = prevEl.textContent.trim();
                if (text.includes('Key findings') || text.includes('Key Findings') ||
                    text.includes('findings indicate') || text.includes('Key metrics')) {
                    const box = document.createElement('div');
                    box.className = 'highlight-box';
                    const title = document.createElement('h3');
                    title.textContent = 'Key Findings:';
                    box.appendChild(title);
                    box.appendChild(ul.cloneNode(true));
                    ul.replaceWith(box);
                }
            }
        });

        // Insert processed HTML
        document.getElementById('article-content').innerHTML = contentDiv.innerHTML;
    </script>
</body>
</html>