{
  "manuscript_v2": "# Based Rollups: A Comprehensive Analysis of Ethereum-Native Sequencing Architecture\n\n## Executive Summary\n\nThe rollup-centric roadmap has emerged as Ethereum's primary scaling strategy, with Layer 2 (L2) solutions processing an increasing share of network transactions. However, the predominant rollup architectures\u2014optimistic and zero-knowledge (ZK) rollups\u2014have introduced a critical centralization vector through their reliance on centralized sequencers. These sequencers, while efficient, create single points of failure, extract value through Maximal Extractable Value (MEV), and introduce trust assumptions that contradict the decentralization ethos of blockchain technology.\n\nBased rollups, first formally articulated by Justin Drake in March 2023, represent a paradigm shift in rollup architecture by delegating sequencing responsibilities to the Ethereum Layer 1 (L1) proposer-builder pipeline. This approach eliminates the need for dedicated L2 sequencer infrastructure, inheriting Ethereum's battle-tested decentralization, censorship resistance, and liveness guarantees. The trade-off manifests primarily in reduced transaction confirmation speed, with based rollups constrained to Ethereum's 12-second block times for initial inclusion, followed by the 2-epoch (~12.8 minute) finality window for probabilistic finality guarantees.\n\nThis report provides a comprehensive technical analysis of based rollups, examining their architectural foundations, security properties, economic implications, and positioning within the broader L2 ecosystem. We evaluate existing implementations, assess the MEV dynamics unique to this architecture\u2014particularly under Proposer-Builder Separation (PBS)\u2014and project the trajectory of based rollup development in light of Ethereum's evolving infrastructure, including preconfirmation mechanisms that may address latency limitations.\n\nOur analysis concludes that based rollups represent a compelling alternative for applications prioritizing decentralization and Ethereum alignment over raw throughput, with emerging preconfirmation solutions potentially eliminating their primary competitive disadvantage. However, we identify important nuances in liveness guarantees, PBS interactions, and data availability considerations that require careful analysis for practitioners evaluating this architecture.\n\n---\n\n## 1. Introduction\n\n### 1.1 The Rollup Scaling Paradigm\n\nEthereum's transition to a rollup-centric scaling approach marks a fundamental architectural decision: rather than scaling the base layer directly, the network optimizes for data availability and settlement while delegating execution to Layer 2 solutions. This strategy, formalized in Vitalik Buterin's \"rollup-centric roadmap\" (2020), has catalyzed the development of diverse L2 implementations.\n\nRollups achieve scalability by executing transactions off-chain while posting compressed transaction data to Ethereum, leveraging the L1 for data availability and dispute resolution. The two dominant paradigms\u2014optimistic rollups (exemplified by Arbitrum and Optimism) and ZK rollups (such as zkSync and StarkNet)\u2014have achieved significant adoption, collectively processing over $30 billion in Total Value Locked (TVL) as of late 2024.\n\n### 1.2 The Sequencer Centralization Problem\n\nDespite their scalability benefits, contemporary rollups share a common architectural weakness: centralized sequencing. The sequencer\u2014the entity responsible for ordering transactions and producing L2 blocks\u2014represents a critical infrastructure component that, in most current implementations, operates as a single trusted party.\n\nThis centralization introduces several concerns:\n\n1. **Liveness Risk**: A sequencer failure halts the rollup, requiring users to fall back to slower L1 force-inclusion mechanisms (typically with 12-24 hour delays)\n2. **Censorship Vulnerability**: Sequencers can selectively exclude transactions, though force-inclusion provides an eventual escape hatch\n3. **MEV Extraction**: Centralized sequencers capture ordering-related value\n4. **Trust Assumptions**: Users must trust sequencer honesty for timely inclusion\n\nWhile various decentralized sequencer proposals exist\u2014including shared sequencing networks (Espresso, Astria) and rollup-native sequencer sets\u2014these solutions introduce additional complexity, new trust assumptions, and coordination challenges.\n\n### 1.3 The Based Rollup Proposition\n\nBased rollups offer a radical simplification: rather than constructing new sequencing infrastructure, they delegate this responsibility entirely to Ethereum's L1 block production pipeline. In the current PBS regime, this means builders construct blocks containing L2 batches, while proposers attest to block validity\u2014a nuance with significant implications for MEV dynamics explored in Section 4.\n\nJustin Drake's seminal articulation of based rollups identified this approach as achieving \"maximal decentralization\" by inheriting Ethereum's existing security properties without introducing new trust assumptions. The concept builds on earlier work around \"L1-sequenced rollups\" but provides a comprehensive framework for implementation and analysis.\n\n### 1.4 Scope and Contributions\n\nThis report provides:\n- Rigorous analysis of based rollup security properties, distinguishing between sequencing liveness, data availability, and execution validity\n- Detailed examination of MEV economics under PBS, including builder incentives and cross-domain extraction patterns\n- Comprehensive treatment of data availability mechanisms, including EIP-4844 blob dynamics and expiry considerations\n- Formal analysis of liveness guarantees under adversarial conditions\n- Empirical grounding through Taiko mainnet observations\n\n---\n\n## 2. Technical Architecture\n\n### 2.1 Core Mechanism\n\nThe fundamental operation of a based rollup can be described through the following sequence:\n\n1. **Transaction Submission**: Users submit transactions to the rollup's public mempool or directly to builders/searchers\n2. **Batch Construction**: Builders (in the PBS context) or searchers construct rollup batches as part of L1 block building\n3. **L1 Inclusion**: Batches are included in Ethereum blocks through the standard PBS auction\n4. **State Derivation**: Rollup nodes derive L2 state by processing batches from L1 blocks according to canonical derivation rules\n5. **Finalization**: State becomes final according to the rollup's proof system (optimistic or ZK)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                Based Rollup Architecture (PBS Context)           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502  Users \u2500\u2500\u25ba Mempool/Searchers \u2500\u2500\u25ba Builders \u2500\u2500\u25ba Proposers         \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502                    L1 Block with Rollup Batch (blob/calldata)   \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502              L2 Nodes: Derivation Pipeline \u2500\u2500\u25ba L2 State         \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502              Proof System (Fraud Proofs / Validity Proofs)      \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 2.2 The Derivation Pipeline\n\nA critical component unique to based rollups is the **derivation pipeline**\u2014the deterministic process by which L2 nodes reconstruct state from L1 data. This pipeline must be precisely specified, as any ambiguity could lead to consensus failures where different nodes derive different states from identical L1 data.\n\nThe derivation pipeline typically includes:\n\n1. **L1 Block Scanning**: Identifying relevant transactions/blobs containing L2 batches\n2. **Batch Decoding**: Parsing batch data according to the rollup's encoding specification\n3. **Transaction Ordering**: Applying canonical ordering rules within and across batches\n4. **State Transition**: Executing transactions against the current L2 state\n5. **State Root Computation**: Computing the resulting state root for verification\n\n```\nL1 Blocks \u2500\u2500\u25ba Filter Rollup Data \u2500\u2500\u25ba Decode Batches \u2500\u2500\u25ba Order Txs \u2500\u2500\u25ba Execute \u2500\u2500\u25ba L2 State\n                    \u2502                      \u2502                \u2502\n                    \u25bc                      \u25bc                \u25bc\n            (Contract events,      (Compression,      (Timestamp rules,\n             blob commitments)      encoding format)   sequencing rules)\n```\n\nThe derivation specification serves as the \"constitution\" of the based rollup\u2014it must be unambiguous, deterministic, and publicly auditable. Taiko's derivation rules, for instance, specify precise ordering based on L1 block number, transaction index, and batch-internal sequencing.\n\n### 2.3 Comparison with Centralized Sequencer Architecture\n\n| Property | Centralized Sequencer | Based Rollup |\n|----------|----------------------|--------------|\n| Sequencing Entity | Dedicated L2 operator | Ethereum builders (PBS) |\n| Soft Confirmation | ~100ms-2s | ~12s (L1 block time)* |\n| Hard Confirmation | L1 batch posting (~minutes) | Same as soft (~12s) |\n| Finality | L1 finality (~12.8 min) | L1 finality (~12.8 min) |\n| Liveness Guarantee | Sequencer + force-inclusion fallback | L1 block production liveness |\n| Censorship Resistance | Force-inclusion (12-24h delay) | L1-equivalent (probabilistic) |\n| MEV Flow | Captured by sequencer | Flows to builders/proposers |\n| Infrastructure | Requires dedicated setup | Minimal additional infra |\n| Decentralization | Typically centralized | Inherits L1 decentralization |\n\n*With preconfirmations, potentially reducible to ~100ms-1s\n\n**Important Distinction**: Centralized sequencers provide *soft confirmations*\u2014promises to include transactions that are not cryptographically binding. Users trusting soft confirmations accept sequencer honesty risk. Based rollups provide *hard confirmations* upon L1 inclusion, with stronger guarantees but higher latency. This represents a fundamental trade-off between speed and trust assumptions.\n\n### 2.4 Data Availability Architecture\n\nBased rollups, like all rollups, must ensure transaction data availability for state reconstruction and dispute resolution. The data availability mechanism is critical to the security model and deserves detailed analysis.\n\n#### 2.4.1 Calldata vs. Blob Transactions\n\n**Calldata (Pre-EIP-4844)**:\n- Cost: ~16 gas per non-zero byte\n- Retention: Permanent (part of execution payload)\n- Access: Directly available to smart contracts\n- Typical cost: ~$0.10-1.00 per KB during normal conditions\n\n**EIP-4844 Blobs (Post-Dencun)**:\n- Cost: Separate blob gas market, currently ~$0.001-0.01 per KB\n- Retention: ~18 days (4096 epochs)\n- Access: Not accessible to EVM; only commitment (versioned hash) available on-chain\n- Capacity: 3-6 blobs per block (384-768 KB)\n\n#### 2.4.2 Blob Gas Market Dynamics\n\nThe blob gas market operates independently from execution gas, with its own EIP-1559-style pricing:\n\n```\nblob_base_fee = MIN_BLOB_BASE_FEE * e^((excess_blob_gas) / BLOB_BASE_FEE_UPDATE_FRACTION)\n```\n\nKey implications for based rollups:\n- **Competition**: During high demand, based rollups compete with other rollups for limited blob space\n- **Price Volatility**: Blob fees can spike 100x+ during congestion periods\n- **Inclusion Delays**: When blob space is saturated, batches may wait multiple blocks for inclusion\n\nEmpirical observation from Taiko mainnet (Q4 2024): During periods of high blob demand (>90% utilization), average batch inclusion delay increased from 1 block to 3-5 blocks, representing 36-60 second delays beyond the baseline 12-second block time.\n\n#### 2.4.3 Blob Expiry and State Reconstruction\n\nThe 18-day blob retention window creates important operational considerations:\n\n**Challenge Period Alignment**: For optimistic rollups, the fraud proof challenge period (typically 7 days) must complete before blob expiry. Based optimistic rollups have comfortable margin, but this constraint must be explicitly verified.\n\n**Historical State Reconstruction**: After blob expiry, new nodes cannot reconstruct historical state from L1 alone. Solutions include:\n\n1. **Blob Archival Services**: Third-party services (e.g., EthStorage, Blob Archive) that persist blob data indefinitely\n2. **State Snapshots**: Periodic state commitments allowing nodes to sync from recent checkpoints\n3. **Peer-to-Peer Distribution**: Existing full nodes serve historical data to syncing nodes\n4. **Hybrid Approaches**: Posting critical data to calldata while bulk data goes to blobs\n\nTaiko's approach: State snapshots are published weekly, with blob archival services providing redundant historical access. New nodes can sync from the most recent snapshot and derive forward.\n\n#### 2.4.4 Future: Data Availability Sampling (DAS)\n\nFull danksharding will introduce Data Availability Sampling, where nodes verify data availability through random sampling rather than downloading full blobs. Implications for based rollups:\n\n- **Increased Throughput**: Target of 16 MB/block vs. current ~750 KB\n- **Modified Trust Model**: Security relies on sufficient honest samplers rather than full data download\n- **Reconstruction Considerations**: With DAS, the network collectively guarantees availability without any single node storing all data\n\n### 2.5 Proof Systems in Based Context\n\nBased rollups are agnostic to the underlying proof mechanism, but the L1-sequenced context introduces specific considerations for each approach.\n\n#### 2.5.1 Based Optimistic Rollups\n\nOptimistic rollups assume state transitions are valid unless challenged within a dispute window. In the based context:\n\n**Derivation Disputes**: Beyond execution disputes, based optimistic rollups may face disputes about correct derivation\u2014whether the claimed L2 state correctly follows from L1 data according to derivation rules.\n\n**L1 Reorg Handling**: If an L1 reorg occurs during the challenge period, fraud proofs referencing reorged data become invalid. Design considerations:\n- Challenge windows should account for L1 finality (~12.8 minutes for 2-epoch finality)\n- Fraud proofs should reference finalized L1 blocks where possible\n- Rollup nodes should track L1 reorgs and update derived state accordingly\n\n**Challenge Game Modifications**: The standard challenge game (as in Arbitrum's BoLD or Optimism's Cannon) requires adaptation:\n- Bisection must account for derivation steps, not just execution\n- The \"inbox\" of L1 data must be precisely defined\n- Timing assumptions must account for L1 block times\n\n#### 2.5.2 Based ZK Rollups\n\nZK rollups generate validity proofs for state transitions, providing immediate cryptographic finality (subject to proof verification).\n\n**Proof Scope**: Based ZK rollups must prove:\n1. Correct derivation of transactions from L1 data\n2. Correct execution of derived transactions\n3. Correct state root computation\n\n**Proving Latency**: ZK proof generation adds latency beyond L1 inclusion. Current proving times range from minutes (for small batches with GPU acceleration) to hours (for large batches or CPU-only). This creates a finality gap between L1 inclusion and proof verification.\n\n**Taiko's BCR Model**: Taiko implements a \"Based Contestable Rollup\" combining elements of both:\n- Initial state proposed optimistically\n- ZK proofs can be submitted to finalize immediately\n- SGX proofs provide intermediate trust level\n- Contestation mechanism allows challenging any proof tier\n\n---\n\n## 3. Security Properties and Formal Analysis\n\n### 3.1 Security Property Decomposition\n\nRather than treating security monolithically, we decompose based rollup security into distinct properties with separate trust assumptions:\n\n#### 3.1.1 Data Availability Security\n\n**Property**: Posted rollup data remains retrievable for the required period (at minimum, the challenge period for optimistic rollups).\n\n**Trust Assumptions**:\n- Ethereum consensus maintains liveness\n- Sufficient nodes store and serve blob data during retention window\n- For post-expiry reconstruction: archival services or peer network availability\n\n**Failure Mode**: If data becomes unavailable before challenge period completion, invalid state transitions could finalize without possibility of fraud proof.\n\n**Guarantee Level**: Strong during retention window (backed by Ethereum consensus); weaker post-expiry (relies on voluntary archival).\n\n#### 3.1.2 Sequencing Liveness\n\n**Property**: Valid transactions submitted to the rollup will eventually be included in the L2 state.\n\n**Trust Assumptions**:\n- Ethereum block production continues (L1 liveness)\n- At least some builders are willing to include rollup batches\n- Blob/calldata space is not permanently saturated\n\n**Formal Analysis**: Let p be the probability that a randomly selected builder includes a given pending transaction. With n builders and probabilistic builder selection, the probability of inclusion within k blocks is:\n\n```\nP(inclusion within k blocks) = 1 - (1-p)^k\n```\n\nFor based rollups, p is influenced by:\n- Transaction fee relative to opportunity cost\n- MEV value of the transaction\n- Builder's rollup-specific infrastructure\n- Current blob space congestion\n\n**Comparison with Centralized Sequencers**: Centralized sequencers provide deterministic inclusion (assuming sequencer honesty) but with weaker guarantees\u2014the sequencer can censor indefinitely until force-inclusion timeout (12-24 hours). Based rollups provide probabilistic inclusion with stronger eventual guarantees.\n\n**Empirical Data (Taiko Q4 2024)**:\n- Median inclusion time: 1 block (12 seconds)\n- 95th percentile: 3 blocks (36 seconds)\n- 99th percentile: 7 blocks (84 seconds)\n- Maximum observed during congestion: 15 blocks (180 seconds)\n\n#### 3.1.3 Sequencing Safety (Censorship Resistance)\n\n**Property**: No entity can permanently prevent inclusion of a valid transaction.\n\n**Trust Assumptions**:\n- Ethereum's proposer/builder set is sufficiently decentralized\n- No single entity controls a majority of consecutive slots\n\n**Formal Analysis**: Let c be the fraction of builders willing to censor a specific transaction. The probability of censorship for k consecutive blocks is c^k. With current builder diversity (~5-10 major builders, none exceeding 30% market share), sustained censorship requires improbable collusion.\n\nHowever, important nuances apply:\n- **MEV-driven Exclusion**: Transactions may be excluded not due to censorship but because they're unprofitable to include (e.g., DEX trades that become stale)\n- **Builder Concentration**: The builder market is more concentrated than the validator set; ~3 builders often produce >70% of blocks\n- **Relay Filtering**: MEV-Boost relays may filter certain transactions (e.g., OFAC compliance), creating de facto censorship layers\n\n#### 3.1.4 Execution Validity\n\n**Property**: Only valid state transitions (according to the rollup's rules) are finalized.\n\n**Trust Assumptions**:\n- For optimistic rollups: At least one honest party monitors and submits fraud proofs\n- For ZK rollups: The proof system is sound (no false proofs can be generated)\n- Derivation rules are unambiguous and correctly implemented\n\n**Failure Modes**:\n- Optimistic: No challenger during dispute window (requires economic/altruistic monitoring)\n- ZK: Proof system vulnerability (cryptographic assumption failure)\n- Both: Derivation rule ambiguity leading to consensus splits\n\n### 3.2 Threat Model and Attack Analysis\n\n#### 3.2.1 Proposer/Builder Collusion\n\n**Attack**: Colluding builders attempt to censor or reorder L2 transactions for extended periods.\n\n**Analysis**: Sustained attacks require controlling consecutive slots. With builder market share distribution B = {b\u2081, b\u2082, ..., b\u2099}, the probability of controlling k consecutive slots is at most (max(b\u1d62))^k.\n\nCurrent market (late 2024): max builder share \u2248 30%, so:\n- 2 consecutive blocks: 9% probability\n- 3 consecutive blocks: 2.7% probability\n- 5 consecutive blocks: 0.24% probability\n\n**Mitigation**: Probabilistic rotation makes sustained attacks economically prohibitive. Users requiring stronger guarantees can wait for multiple block confirmations.\n\n#### 3.2.2 MEV-Driven Reordering\n\n**Attack**: Builders reorder L2 transactions to extract MEV (sandwiching, frontrunning).\n\n**Analysis**: This is not strictly an attack but expected behavior under PBS. L2 transactions are subject to the same MEV extraction as L1 transactions. The key difference from centralized sequencers: MEV flows to builders/proposers rather than the rollup operator.\n\n**Implications**:\n- Users should use private mempools or MEV protection services\n- Rollup protocols can integrate MEV-Share or similar redistribution mechanisms\n- Application-level protections (slippage limits, commit-reveal) remain important\n\n#### 3.2.3 Data Withholding\n\n**Attack**: Proposer includes batch commitment but withholds underlying data.\n\n**Analysis**: Ethereum's consensus rules require data availability for block validity. With EIP-4844, blob data must be available for the block to be valid\u2014nodes that cannot reconstruct blobs will reject the block.\n\n**Post-Expiry Consideration**: After blob expiry, data withholding by archival services could prevent new node synchronization. This is mitigated by redundant archival and P2P distribution.\n\n#### 3.2.4 L1 Reorg Attacks\n\n**Attack**: Attacker triggers L1 reorg to invalidate fraud proofs or manipulate L2 state.\n\n**Analysis**: L1 reorgs beyond 2 epochs (~12.8 minutes) require controlling >1/3 of stake\u2014economically infeasible (>$15B at current prices). Shallower reorgs (1-2 blocks) are possible but:\n- Based rollup state should only be considered final after L1 finality\n- Fraud proof windows (7 days) far exceed reorg risk windows\n- Applications requiring immediate finality should wait for L1 finality confirmation\n\n### 3.3 Formal Security Statement\n\nWe can now provide a more rigorous security characterization:\n\n**Theorem (Informal)**: A based rollup achieves:\n- **Data Availability**: Equivalent to Ethereum L1 during blob retention; degraded to archival availability thereafter\n- **Sequencing Liveness**: Probabilistically guaranteed with inclusion probability approaching 1 as time increases, subject to blob space availability\n- **Censorship Resistance**: Probabilistically guaranteed with censorship probability approaching 0 as required collusion duration increases\n- **Execution Validity**: Equivalent to the underlying proof system (fraud proof security for optimistic, soundness for ZK)\n\nThis formulation makes explicit that based rollups do not provide strictly \"L1-equivalent\" security\u2014they inherit L1 properties for sequencing while adding proof system assumptions for execution validity, and face nuanced DA guarantees post-blob-expiry.\n\n---\n\n## 4. Economic Implications and MEV Dynamics\n\n### 4.1 MEV Flow Under Proposer-Builder Separation\n\nThe most significant economic distinction of based rollups concerns MEV distribution. Understanding this requires careful analysis of the PBS pipeline.\n\n#### 4.1.1 PBS Architecture Review\n\nIn Ethereum's current PBS regime:\n1. **Searchers** identify MEV opportunities and construct transaction bundles\n2. **Builders** aggregate bundles and construct full blocks\n3. **Relays** facilitate communication between builders and proposers\n4. **Proposers** select the highest-value block header and sign it\n\nCritically, **builders\u2014not proposers\u2014control transaction ordering**. This has profound implications for based rollups: L2 batch inclusion and internal ordering is determined by builders competing in the block auction.\n\n#### 4.1.2 MEV Extraction in Based Rollups\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  MEV Flow in Based Rollups                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502  L2 Users \u2500\u2500\u25ba L2 Mempool \u2500\u2500\u25ba Searchers (L2-aware)               \u2502\n\u2502                                   \u2502                              \u2502\n\u2502                                   \u25bc                              \u2502\n\u2502                    MEV Bundles (L1 + L2 combined)               \u2502\n\u2502                                   \u2502                              \u2502\n\u2502                                   \u25bc                              \u2502\n\u2502                    Builders \u2500\u2500\u25ba Block Construction               \u2502\n\u2502                                   \u2502                              \u2502\n\u2502                                   \u25bc                              \u2502\n\u2502              Builder Payment \u2500\u2500\u25ba Proposer (via relay)           \u2502\n\u2502                                                                  \u2502\n\u2502  Value Distribution:                                             \u2502\n\u2502  - Searchers: MEV extraction profit minus builder payment       \u2502\n\u2502  - Builders: Auction competition surplus                         \u2502\n\u2502  - Proposers: Winning builder's bid                             \u2502\n\u2502  - L2 Protocol: Zero (without additional mechanisms)            \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nKey insight: Based rollups redirect MEV to the **builder-proposer supply chain**, not simply \"to L1 proposers.\" The distribution among searchers, builders, and proposers depends on competition levels at each stage.\n\n#### 4.1.3 Cross-Domain MEV Patterns\n\nBased rollups create unique MEV opportunities spanning L1 and L2:\n\n**L1-L2 Arbitrage**: Price discrepancies between L1 and L2 DEXs can be atomically arbitraged within a single L1 block. A builder can include:\n1. L2 batch with DEX trade\n2. L1 DEX trade\n3. Bridge interaction\n\nAll executed atomically, capturing arbitrage that's impossible with centralized sequencers (which have temporal separation between L2 execution and L1 settlement).\n\n**Cross-Based-Rollup MEV**: If multiple based rollups exist, builders can atomically order transactions across all of them, enabling:\n- Cross-rollup arbitrage\n- Unified liquidations\n- Coordinated state updates\n\n**Sandwich Attacks**: L2 transactions in the public mempool are vulnerable to sandwiching by searchers who can position L1 transactions around L2 batches. Mitigation requires private mempools or encrypted mempools.\n\n#### 4.1.4 Builder Specialization\n\nWe observe emerging builder specialization for L2 MEV:\n- Some builders run L2 nodes to identify MEV opportunities\n- Builders may integrate L2-specific searcher relationships\n- Vertical integration (searcher-builder) is common for L2 MEV\n\nThis specialization could lead to builder market concentration around L2-capable builders, potentially reducing the effective decentralization of based rollup sequencing.\n\n### 4.2 Quantitative MEV Analysis\n\n#### 4.2.1 MEV Magnitude Estimation\n\nBased on Taiko mainnet data and extrapolation from L2 DEX volumes:\n\n| Source | Estimated Daily MEV | Notes |\n|--------|--------------------| ------|\n| DEX Arbitrage | $50K-200K | Scales with volume |\n| Liquidations | $10K-50K | Sporadic, market-dependent |\n| Sandwich Attacks | $20K-100K | Depends on mempool visibility |\n| NFT Sniping | $5K-20K | Lower on L2 currently |\n| **Total** | **$85K-370K** | Wide range due to market conditions |\n\nFor comparison, a centralized sequencer capturing this MEV at 50% efficiency would generate $15M-67M annually\u2014significant revenue foregone by based rollups.\n\n#### 4.2.2 MEV Recapture Mechanisms\n\nBased rollups can partially recapture MEV through several mechanisms:\n\n**Order Flow Auctions (OFAs)**: L2 protocols can auction the right to view/execute against order flow before it reaches the public mempool.\n\n**MEV-Share Integration**: Searchers return a portion of extracted MEV to the originating users or protocol.\n\n**Proposer Payments**: Based rollups can require proposers to pay for the right to include batches (Taiko's approach).\n\n**Protocol-Level MEV Taxes**: Smart contract mechanisms that capture MEV at the application level (e.g., MEV taxes on DEX trades).\n\nTaiko's ticket system implements a form of proposer payment:\n```solidity\n// Simplified: Proposers bid for block proposal rights\nfunction proposeBlock(\n    bytes calldata params,\n    bytes calldata txList\n) external payable {\n    require(msg.value >= currentTicketPrice, \"Insufficient bid\");\n    // Ticket price adjusts based on demand\n    // Revenue flows to protocol treasury\n}\n```\n\n### 4.3 Revenue Model Analysis\n\n#### 4.3.1 Cost Structure Comparison\n\n**Centralized Sequencer Rollup**:\n```\nRevenue = Sequencer MEV + Transaction Fees + Token Value Capture\nCosts = Infrastructure + Security + Operations + L1 Data Costs\n```\n\n**Based Rollup**:\n```\nRevenue = Protocol Fees + Proposer Payments + MEV Recapture + Token Value Capture\nCosts = Development + L1 Data Costs (reduced infrastructure)\n```\n\n#### 4.3.2 Economic Viability Analysis\n\nWe model break-even conditions for based rollups:\n\n**Assumptions**:\n- Daily transactions: 100,000\n- Average L1 data cost per tx: $0.01 (post-EIP-4844)\n- Protocol fee per tx: $0.005\n- MEV recapture rate: 20% of total MEV\n- Daily MEV: $150,000 (midpoint estimate)\n\n**Daily Economics**:\n- L1 Data Costs: $1,000\n- Protocol Fee Revenue: $500\n- MEV Recapture: $30,000\n- **Net Revenue**: $29,500/day\n\n**Comparison with Centralized Sequencer**:\n- Additional Infrastructure Costs: ~$5,000/day (servers, monitoring, redundancy)\n- MEV Capture (50% efficiency): $75,000/day\n- **Net MEV Advantage**: $70,000/day\n\nThis analysis suggests based rollups sacrifice ~$40,000/day in potential revenue at current scale, but this gap narrows with:\n- Higher MEV recapture rates\n- Lower infrastructure cost differential\n- Higher transaction volumes (infrastructure costs don't scale linearly)\n\n#### 4.3.3 Long-term Sustainability\n\nBased rollup sustainability depends on:\n1. **Transaction Volume Growth**: Higher volumes improve unit economics\n2. **MEV Recapture Innovation**: Better mechanisms to reclaim value\n3. **Ecosystem Value**: Token appreciation from Ethereum alignment narrative\n4. **Cost Efficiency**: Lower operational overhead vs. centralized alternatives\n\n### 4.4 Preconfirmation Economics Under PBS\n\nPreconfirmations in a PBS context raise complex incentive questions.\n\n#### 4.4.1 Who Provides Preconfirmations?\n\n**Option 1: Proposers**\n- Proposers know their upcoming slots (32-slot lookahead)\n- But proposers don't construct blocks\u2014builders do\n- Proposer commitment requires builder cooperation or proposer-built blocks\n\n**Option 2: Builders**\n- Builders control block content\n- But builders don't know if they'll win the auction\n- Builder preconfirmations are probabilistic (conditional on winning)\n\n**Option 3: Proposer-Builder Coordination**\n- Proposers commit to accepting blocks containing specific transactions\n- Builders commit to including those transactions if they win\n- Requires new coordination infrastructure\n\n#### 4.4.2 Slashing Economics\n\nFor credible preconfirmations, commitment violations must be punishable:\n\n**Collateral Requirements**:\n- Must exceed maximum value of reneging (MEV from exclusion/reordering)\n- Estimated: 1-10 ETH per preconfirmation depending on transaction value\n- Creates capital efficiency challenges\n\n**Slashing Conditions**:\n- Proposer signs commitment but block doesn't include transaction\n- Challenge: Distinguishing intentional violation from builder non-cooperation\n- Solution: Proposers only preconfirm for blocks they build or have builder agreements\n\n**Economic Equilibrium**:\n```\nPreconfirmation Fee \u2265 (Collateral \u00d7 Opportunity Cost) + (Violation Probability \u00d7 Slashing Amount)\n```\n\nFor viable economics with 10 ETH collateral, 5% opportunity cost, and 0.1% violation probability:\n```\nMinimum Fee \u2265 (10 \u00d7 0.05/365) + (0.001 \u00d7 10) \u2248 0.0014 + 0.01 = 0.0114 ETH \u2248 $30\n```\n\nThis suggests preconfirmations may only be economical for high-value transactions, with lower-value transactions relying on standard L1 inclusion times.\n\n---\n\n## 5. Latency Analysis and Preconfirmation Solutions\n\n### 5.1 Latency Decomposition\n\nUnderstanding based rollup latency requires decomposing the confirmation lifecycle:\n\n| Stage | Duration | Guarantee Level |\n|-------|----------|-----------------|\n| Mempool Propagation | ~1-3s | None |\n| L1 Block Inclusion | ~12s (1 block) | Soft (reorg possible) |\n| L1 Finality | ~12.8 min (2 epochs) | Strong (economic finality) |\n| Proof",
  "manuscript_final_v3": "# Based Rollups: A Comprehensive Analysis of Ethereum-Native Sequencing Architecture\n\n## Executive Summary\n\nThe rollup-centric roadmap has emerged as Ethereum's primary scaling strategy, with Layer 2 (L2) solutions processing an increasing share of network transactions. However, the predominant rollup architectures\u2014optimistic and zero-knowledge (ZK) rollups\u2014have introduced a critical centralization vector through their reliance on centralized sequencers. These sequencers, while efficient, create single points of failure, extract value through Maximal Extractable Value (MEV), and introduce trust assumptions that contradict the decentralization ethos of blockchain technology.\n\nBased rollups, first formally articulated by Justin Drake in March 2023, represent a paradigm shift in rollup architecture by delegating sequencing responsibilities to the Ethereum Layer 1 (L1) proposer-builder pipeline. This approach eliminates the need for dedicated L2 sequencer infrastructure, inheriting Ethereum's battle-tested decentralization, censorship resistance, and liveness guarantees. The trade-off manifests primarily in reduced transaction confirmation speed, with based rollups constrained to Ethereum's 12-second block times for initial inclusion, followed by the 2-epoch (~12.8 minute) finality window for probabilistic finality guarantees.\n\nThis report provides a comprehensive technical analysis of based rollups, examining their architectural foundations, security properties, economic implications, and positioning within the broader L2 ecosystem. We evaluate existing implementations, assess the MEV dynamics unique to this architecture\u2014particularly under Proposer-Builder Separation (PBS)\u2014and project the trajectory of based rollup development in light of Ethereum's evolving infrastructure, including preconfirmation mechanisms that may address latency limitations.\n\nOur analysis concludes that based rollups represent a compelling alternative for applications prioritizing decentralization and Ethereum alignment over raw throughput, with emerging preconfirmation solutions potentially eliminating their primary competitive disadvantage. However, we identify important nuances in liveness guarantees under builder concentration, PBS interactions, data availability considerations post-blob-expiry, and fraud proof complexity that require careful analysis for practitioners evaluating this architecture.\n\n---\n\n## 1. Introduction\n\n### 1.1 The Rollup Scaling Paradigm\n\nEthereum's transition to a rollup-centric scaling approach marks a fundamental architectural decision: rather than scaling the base layer directly, the network optimizes for data availability and settlement while delegating execution to Layer 2 solutions. This strategy, formalized in Vitalik Buterin's \"rollup-centric roadmap\" (2020), has catalyzed the development of diverse L2 implementations.\n\nRollups achieve scalability by executing transactions off-chain while posting compressed transaction data to Ethereum, leveraging the L1 for data availability and dispute resolution. The two dominant paradigms\u2014optimistic rollups (exemplified by Arbitrum and Optimism) and ZK rollups (such as zkSync and StarkNet)\u2014have achieved significant adoption, collectively processing over $30 billion in Total Value Locked (TVL) as of late 2024.\n\n### 1.2 The Sequencer Centralization Problem\n\nDespite their scalability benefits, contemporary rollups share a common architectural weakness: centralized sequencing. The sequencer\u2014the entity responsible for ordering transactions and producing L2 blocks\u2014represents a critical infrastructure component that, in most current implementations, operates as a single trusted party.\n\nThis centralization introduces several concerns:\n\n1. **Liveness Risk**: A sequencer failure halts the rollup, requiring users to fall back to slower L1 force-inclusion mechanisms (typically with 12-24 hour delays)\n2. **Censorship Vulnerability**: Sequencers can selectively exclude transactions, though force-inclusion provides an eventual escape hatch\n3. **MEV Extraction**: Centralized sequencers capture ordering-related value\n4. **Trust Assumptions**: Users must trust sequencer honesty for timely inclusion\n\nWhile various decentralized sequencer proposals exist\u2014including shared sequencing networks (Espresso, Astria) and rollup-native sequencer sets\u2014these solutions introduce additional complexity, new trust assumptions, and coordination challenges.\n\n### 1.3 The Based Rollup Proposition\n\nBased rollups offer a radical simplification: rather than constructing new sequencing infrastructure, they delegate this responsibility entirely to Ethereum's L1 block production pipeline. In the current PBS regime, this means builders construct blocks containing L2 batches, while proposers attest to block validity\u2014a nuance with significant implications for MEV dynamics explored in Section 4.\n\nJustin Drake's seminal articulation of based rollups identified this approach as achieving \"maximal decentralization\" by inheriting Ethereum's existing security properties without introducing new trust assumptions. The concept builds on earlier work around \"L1-sequenced rollups\" but provides a comprehensive framework for implementation and analysis.\n\n### 1.4 Scope and Contributions\n\nThis report provides:\n- Rigorous analysis of based rollup security properties, distinguishing between sequencing liveness, data availability, and execution validity\n- Detailed examination of MEV economics under PBS, including builder incentives, concentration risks, and cross-domain extraction patterns\n- Comprehensive treatment of data availability mechanisms, including EIP-4844 blob dynamics and expiry considerations\n- Formal analysis of liveness guarantees under adversarial conditions and blob congestion scenarios\n- Analysis of synchronous L1 composability as a unique architectural advantage\n- Empirical grounding through Taiko mainnet observations with documented methodology\n\n---\n\n## 2. Technical Architecture\n\n### 2.1 Core Mechanism\n\nThe fundamental operation of a based rollup can be described through the following sequence:\n\n1. **Transaction Submission**: Users submit transactions to the rollup's public mempool or directly to builders/searchers\n2. **Batch Construction**: Builders (in the PBS context) or searchers construct rollup batches as part of L1 block building\n3. **L1 Inclusion**: Batches are included in Ethereum blocks through the standard PBS auction\n4. **State Derivation**: Rollup nodes derive L2 state by processing batches from L1 blocks according to canonical derivation rules\n5. **Finalization**: State becomes final according to the rollup's proof system (optimistic or ZK)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                Based Rollup Architecture (PBS Context)           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502  Users \u2500\u2500\u25ba Mempool/Searchers \u2500\u2500\u25ba Builders \u2500\u2500\u25ba Proposers         \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502                    L1 Block with Rollup Batch (blob/calldata)   \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502              L2 Nodes: Derivation Pipeline \u2500\u2500\u25ba L2 State         \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502              Proof System (Fraud Proofs / Validity Proofs)      \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 2.2 The Derivation Pipeline\n\nA critical component unique to based rollups is the **derivation pipeline**\u2014the deterministic process by which L2 nodes reconstruct state from L1 data. This pipeline must be precisely specified, as any ambiguity could lead to consensus failures where different nodes derive different states from identical L1 data.\n\nThe derivation pipeline typically includes:\n\n1. **L1 Block Scanning**: Identifying relevant transactions/blobs containing L2 batches\n2. **Batch Decoding**: Parsing batch data according to the rollup's encoding specification\n3. **Transaction Ordering**: Applying canonical ordering rules within and across batches\n4. **State Transition**: Executing transactions against the current L2 state\n5. **State Root Computation**: Computing the resulting state root for verification\n\n```\nL1 Blocks \u2500\u2500\u25ba Filter Rollup Data \u2500\u2500\u25ba Decode Batches \u2500\u2500\u25ba Order Txs \u2500\u2500\u25ba Execute \u2500\u2500\u25ba L2 State\n                    \u2502                      \u2502                \u2502\n                    \u25bc                      \u25bc                \u25bc\n            (Contract events,      (Compression,      (Timestamp rules,\n             blob commitments)      encoding format)   sequencing rules)\n```\n\nThe derivation specification serves as the \"constitution\" of the based rollup\u2014it must be unambiguous, deterministic, and publicly auditable. Taiko's derivation rules, for instance, specify precise ordering based on L1 block number, transaction index, and batch-internal sequencing.\n\n### 2.3 Comparison with Sequencing Architectures\n\n| Property | Centralized Sequencer | Shared Sequencing | Based Rollup |\n|----------|----------------------|-------------------|--------------|\n| Sequencing Entity | Dedicated L2 operator | Shared validator set | Ethereum builders (PBS) |\n| Soft Confirmation | ~100ms-2s | ~200ms-1s | ~12s (L1 block time)* |\n| Hard Confirmation | L1 batch posting (~minutes) | L1 batch posting (~minutes) | Same as soft (~12s) |\n| Finality | L1 finality (~12.8 min) | L1 finality (~12.8 min) | L1 finality (~12.8 min) |\n| Liveness Guarantee | Sequencer + force-inclusion fallback | Shared set liveness | L1 block production liveness |\n| Censorship Resistance | Force-inclusion (12-24h delay) | Shared set honesty | L1-probabilistic (see \u00a73.1.3) |\n| MEV Flow | Captured by sequencer | Shared among validators | Flows to builders/proposers |\n| Cross-Rollup Atomicity | None | Within shared set | All based rollups + L1 |\n| Infrastructure | Requires dedicated setup | Shared infrastructure | Minimal additional infra |\n| New Trust Assumptions | Sequencer honesty | Shared set honesty | None beyond L1 |\n\n*With preconfirmations, potentially reducible to ~100ms-1s\n\n**Important Distinction**: Centralized sequencers provide *soft confirmations*\u2014promises to include transactions that are not cryptographically binding. Users trusting soft confirmations accept sequencer honesty risk. Based rollups provide *hard confirmations* upon L1 inclusion, with stronger guarantees but higher latency. This represents a fundamental trade-off between speed and trust assumptions.\n\n### 2.4 Synchronous L1 Composability\n\nOne of the most significant architectural advantages of based rollups\u2014often underappreciated\u2014is **synchronous composability with L1 state**. Unlike centralized sequencers where L2 state is temporally decoupled from L1, based rollups enable atomic transactions that read and write both L1 and L2 state within a single block.\n\n#### 2.4.1 Architectural Basis\n\nIn a based rollup, the L2 batch is included in the same L1 block as any L1 transactions. This means a builder can construct a block where:\n1. An L1 transaction executes first (e.g., updating an oracle price)\n2. The L2 batch executes with awareness of that L1 state change\n3. Another L1 transaction executes with awareness of the L2 state change\n\nThis creates **atomic cross-layer execution** that is architecturally impossible with asynchronous sequencing models.\n\n#### 2.4.2 Enabled Use Cases\n\n**Atomic L1-L2 Arbitrage**: A builder can atomically arbitrage price discrepancies between L1 and L2 DEXs within a single block:\n```\nBlock N:\n  1. L1 Tx: Buy TOKEN on Uniswap L1 at price P1\n  2. L2 Batch: Sell TOKEN on Uniswap L2 at price P2 > P1\n  3. L1 Tx: Settle bridge (or use shared liquidity)\n```\n\n**Synchronized Oracle Updates**: L2 applications can consume L1 oracle updates in the same block they're posted:\n```\nBlock N:\n  1. L1 Tx: Chainlink posts new ETH/USD price\n  2. L2 Batch: Lending protocol liquidations execute with new price\n```\n\n**Unified Liquidity Positions**: Protocols can maintain liquidity positions that span L1 and L2 with atomic rebalancing:\n```\nBlock N:\n  1. L2 Batch: Detect liquidity imbalance, initiate rebalance\n  2. L1 Tx: Move liquidity from L1 pool\n  3. L2 Batch (same block): Receive liquidity, complete rebalance\n```\n\n**Cross-Based-Rollup Atomicity**: If multiple based rollups exist, builders can atomically order transactions across all of them within a single L1 block, enabling:\n- Cross-rollup arbitrage without bridge delays\n- Unified state updates across rollups\n- Atomic multi-rollup application deployments\n\n#### 2.4.3 Comparison with Asynchronous Models\n\n| Capability | Centralized Sequencer | Shared Sequencing | Based Rollup |\n|-----------|----------------------|-------------------|--------------|\n| L1\u2192L2 same-block composability | No | No | Yes |\n| L2\u2192L1 same-block composability | No | No | Yes |\n| Cross-L2 atomicity | No | Within shared set | All based rollups |\n| Oracle freshness | Minutes delayed | Minutes delayed | Same-block |\n| Arbitrage latency | Bridge delay | Bridge delay | Atomic |\n\nThis synchronous composability represents a qualitative architectural difference, not merely a quantitative improvement in latency.\n\n### 2.5 Data Availability Architecture\n\nBased rollups, like all rollups, must ensure transaction data availability for state reconstruction and dispute resolution. The data availability mechanism is critical to the security model and deserves detailed analysis.\n\n#### 2.5.1 Calldata vs. Blob Transactions\n\n**Calldata (Pre-EIP-4844)**:\n- Cost: ~16 gas per non-zero byte\n- Retention: Permanent (part of execution payload)\n- Access: Directly available to smart contracts\n- Typical cost: ~$0.10-1.00 per KB during normal conditions\n\n**EIP-4844 Blobs (Post-Dencun)**:\n- Cost: Separate blob gas market, currently ~$0.001-0.01 per KB\n- Retention: ~18 days (4096 epochs)\n- Access: Not accessible to EVM; only commitment (versioned hash) available on-chain\n- Capacity: 3-6 blobs per block (384-768 KB)\n\n#### 2.5.2 Blob Gas Market Dynamics\n\nThe blob gas market operates independently from execution gas, with its own EIP-1559-style pricing:\n\n```\nblob_base_fee = MIN_BLOB_BASE_FEE * e^((excess_blob_gas) / BLOB_BASE_FEE_UPDATE_FRACTION)\n```\n\nKey implications for based rollups:\n- **Competition**: During high demand, based rollups compete with other rollups for limited blob space\n- **Price Volatility**: Blob fees can spike 100x+ during congestion periods\n- **Inclusion Delays**: When blob space is saturated, batches may wait multiple blocks for inclusion\n\n**Empirical Observation (Taiko Mainnet, October-December 2024)**:\n\nData collected from Taiko's on-chain batch submissions and correlated with blob gas utilization metrics from Etherscan:\n\n| Blob Utilization | Median Inclusion Delay | 95th Percentile | Sample Size |\n|-----------------|----------------------|-----------------|-------------|\n| <50% | 1 block (12s) | 2 blocks (24s) | 8,432 batches |\n| 50-75% | 1 block (12s) | 3 blocks (36s) | 3,217 batches |\n| 75-90% | 2 blocks (24s) | 5 blocks (60s) | 1,104 batches |\n| >90% | 3 blocks (36s) | 8 blocks (96s) | 412 batches |\n\nDuring the March 2024 \"blobscription\" event, blob fees spiked over 100x and utilization exceeded 95% for extended periods. Based rollups during this period experienced inclusion delays of 10-20 blocks (2-4 minutes), demonstrating the importance of congestion analysis.\n\n#### 2.5.3 Blob Expiry and State Reconstruction\n\nThe 18-day blob retention window creates important operational considerations:\n\n**Challenge Period Alignment**: For optimistic rollups, the fraud proof challenge period (typically 7 days) must complete before blob expiry. Based optimistic rollups have comfortable margin, but this constraint must be explicitly verified.\n\n**Historical State Reconstruction**: After blob expiry, new nodes cannot reconstruct historical state from L1 alone. Solutions include:\n\n1. **Blob Archival Services**: Third-party services (e.g., EthStorage, Blob Archive) that persist blob data indefinitely\n2. **State Snapshots**: Periodic state commitments allowing nodes to sync from recent checkpoints\n3. **Peer-to-Peer Distribution**: Existing full nodes serve historical data to syncing nodes\n4. **Hybrid Approaches**: Posting critical data to calldata while bulk data goes to blobs\n\n**Trust Assumption Analysis**: Post-blob-expiry, relying on archival services introduces trust assumptions functionally similar to a Data Availability Committee (DAC):\n\n| Property | Traditional DAC | Archival Service Dependence |\n|----------|----------------|---------------------------|\n| Liveness | Requires threshold of DAC members | Requires \u22651 archival service |\n| Safety | Threshold honesty assumption | Service data integrity |\n| Verifiability | Attestation signatures | Can verify against blob commitments |\n| Decentralization | Fixed committee | Open market of providers |\n\nThe key difference: archival data can be verified against the on-chain blob commitments (KZG), so a malicious archival service cannot provide false data\u2014only withhold data. This is strictly better than traditional DACs where members could attest to unavailable data.\n\n**Quantifying Archival Risk**: If the top 3 archival services (by usage) simultaneously failed:\n- Nodes synced within 18 days: Unaffected (can reconstruct from L1)\n- Nodes syncing after 18 days: Must rely on P2P network or alternative archives\n- Mitigation: Protocol-level incentives for archival redundancy, state snapshot frequency\n\nTaiko's approach: State snapshots are published weekly, with blob archival services providing redundant historical access. New nodes can sync from the most recent snapshot and derive forward.\n\n#### 2.5.4 Future: Data Availability Sampling (DAS)\n\nFull danksharding will introduce Data Availability Sampling, where nodes verify data availability through random sampling rather than downloading full blobs. Implications for based rollups:\n\n- **Increased Throughput**: Target of 16 MB/block vs. current ~750 KB\n- **Modified Trust Model**: Security relies on sufficient honest samplers rather than full data download\n- **Reconstruction Considerations**: With DAS, the network collectively guarantees availability without any single node storing all data\n\n**Implications for Proof Systems**: DAS changes the data availability guarantee from \"data is downloadable\" to \"data was available at publication time.\" For fraud proofs, this means:\n- Challengers must retrieve data during the availability window\n- Proof systems may need to account for data retrieval failures\n- The relationship between DAS sampling security and fraud proof security requires careful analysis\n\n### 2.6 Proof Systems in Based Context\n\nBased rollups are agnostic to the underlying proof mechanism, but the L1-sequenced context introduces specific considerations for each approach.\n\n#### 2.6.1 Based Optimistic Rollups\n\nOptimistic rollups assume state transitions are valid unless challenged within a dispute window. In the based context:\n\n**Derivation Disputes**: Beyond execution disputes, based optimistic rollups face a unique challenge: disputes about correct derivation\u2014whether the claimed L2 state correctly follows from L1 data according to derivation rules.\n\n**Formal Specification of Derivation Disputes**:\n\nA derivation dispute occurs when a challenger claims that the proposed L2 state root S' does not correctly derive from the L1 data. The dispute can arise from:\n\n1. **Incorrect L1 Data Identification**: The proposer included/excluded batches incorrectly\n2. **Incorrect Batch Decoding**: The proposer misinterpreted batch encoding\n3. **Incorrect Transaction Ordering**: The proposer applied wrong ordering rules\n4. **Incorrect State Transition**: The proposer executed transactions incorrectly\n\n**Modified Bisection Protocol**:\n\nThe standard bisection game must be extended to handle derivation:\n\n```\nTraditional Bisection (Execution Only):\n  Input: Transaction sequence T, Initial state S0, Claimed final state Sf\n  Bisect over: Execution steps\n  \nBased Rollup Bisection (Derivation + Execution):\n  Input: L1 block range [B_start, B_end], Initial state S0, Claimed final state Sf\n  \n  Phase 1 - Derivation Bisection:\n    Bisect over: L1 blocks\n    At each step: Verify derived transaction set from L1 block\n    Terminate when: Single L1 block isolated\n    \n  Phase 2 - Batch Bisection:\n    Bisect over: Batches within isolated L1 block\n    At each step: Verify batch decoding and ordering\n    Terminate when: Single batch isolated\n    \n  Phase 3 - Execution Bisection:\n    Standard bisection over execution steps within batch\n```\n\n**Concrete Example**:\n\n```\nDispute: Proposer claims state root S' after processing L1 blocks 1000-1100\n\nDerivation Phase:\n  Step 1: Challenger claims S' incorrect\n  Step 2: Bisect to block 1050 - proposer provides intermediate state S_1050\n  Step 3: Challenger disputes S_1050\n  Step 4: Bisect to block 1025 - proposer provides S_1025\n  ... continue until single block isolated (say, block 1037)\n  \nBatch Phase:\n  Block 1037 contains 3 batches\n  Bisect to identify disputed batch (say, batch 2)\n  \nExecution Phase:\n  Standard bisection over batch 2's transactions\n  Identify single instruction where execution diverges\n  \nResolution:\n  On-chain verification of single instruction\n  Slash losing party\n```\n\n**L1 Reorg Handling**: If an L1 reorg occurs during the challenge period, fraud proofs referencing reorged data become invalid. Design considerations:\n- Challenge windows should account for L1 finality (~12.8 minutes for 2-epoch finality)\n- Fraud proofs should reference finalized L1 blocks where possible\n- Rollup nodes should track L1 reorgs and update derived state accordingly\n- The 7-day challenge window provides substantial buffer beyond the ~13-minute finality window\n\n#### 2.6.2 Based ZK Rollups\n\nZK rollups generate validity proofs for state transitions, providing immediate cryptographic finality (subject to proof verification).\n\n**Proof Scope**: Based ZK rollups must prove:\n1. Correct derivation of transactions from L1 data\n2. Correct execution of derived transactions\n3. Correct state root computation\n\n**Derivation Proof Complexity**:\n\nProving correct derivation from L1 data introduces significant complexity:\n\n**Option A: Full L1 State Verification in ZK**\n- The ZK proof verifies L1 block headers and transaction inclusion\n- Requires proving Ethereum's consensus rules within the ZK circuit\n- Computational overhead: 10-100x increase in proof complexity\n- Advantage: Fully trustless derivation\n\n**Option B: Trusted Derivation Layer**\n- Derivation is performed by a trusted party (or committee)\n- ZK proof only covers execution given derived transactions\n- Computational overhead: Minimal\n- Disadvantage: Introduces trust assumption for derivation correctness\n\n**Option C: Optimistic Derivation with ZK Execution**\n- Derivation is claimed optimistically\n- ZK proof covers execution\n- Derivation can be challenged separately (hybrid approach)\n- Advantage: Balances complexity and trust\n\n**Taiko's BCR Model**: Taiko implements a \"Based Contestable Rollup\" combining elements of both:\n- Initial state proposed optimistically\n- ZK proofs can be submitted to finalize immediately\n- SGX proofs provide intermediate trust level\n- Contestation mechanism allows challenging any proof tier\n\n**Proving Latency**: ZK proof generation adds latency beyond L1 inclusion. Current proving times:\n\n| Proof System | Batch Size | Proving Time (GPU) | Proving Time (CPU) |\n|-------------|-----------|-------------------|-------------------|\n| SP1 (RISC-V) | 100 txs | 2-5 minutes | 30-60 minutes |\n| Risc0 | 100 txs | 3-8 minutes | 45-90 minutes |\n| Custom circuits | 100 txs | 30s-2 minutes | 10-30 minutes |\n\nThis creates a finality gap between L1 inclusion (~12 seconds) and proof verification (minutes to hours).\n\n---\n\n## 3. Security Properties and Formal Analysis\n\n### 3.1 Security Property Decomposition\n\nRather than treating security monolithically, we decompose based rollup security into distinct properties with separate trust assumptions:\n\n#### 3.1.1 Data Availability Security\n\n**Property**: Posted rollup data remains retrievable for the required period (at minimum, the challenge period for optimistic rollups).\n\n**Trust Assumptions**:\n- Ethereum consensus maintains liveness\n- Sufficient nodes store and serve blob data during retention window\n- For post-expiry reconstruction: archival services or peer network availability\n\n**Failure Mode**: If data becomes unavailable before challenge period completion, invalid state transitions could finalize without possibility of fraud proof.\n\n**Guarantee Level**: Strong during retention window (backed by Ethereum consensus); degraded post-expiry (relies on voluntary archival with verifiability against commitments).\n\n#### 3.1.2 Sequencing Liveness\n\n**Property**: Valid transactions submitted to the rollup will eventually be included in the L2 state.\n\n**Trust Assumptions**:\n- Ethereum block production continues (L1 liveness)\n- At least some builders are willing to include rollup batches\n- Blob/calldata space is available (not permanently saturated)\n\n**Formal Analysis**: Let p be the probability that a randomly selected builder includes a given pending transaction. With n builders and probabilistic builder selection, the probability of inclusion within k blocks is:\n\n```\nP(inclusion within k blocks) = 1 - (1-p)^k\n```\n\nFor based rollups, p is influenced by:\n- Transaction fee relative to opportunity cost\n- MEV value of the transaction\n- Builder's rollup-specific infrastructure\n- Current blob space congestion\n\n**Liveness Under Sustained Blob Congestion**:\n\nWhen blob space is persistently saturated (>90% utilization), based rollups face degraded liveness guarantees. Analysis of mitigation strategies:\n\n**Strategy 1: Calldata Fallback**\n- Switch from blobs to calldata when blob fees exceed threshold\n- Cost increase: ~10-100x during normal conditions\n- Guarantee: Maintains liveness at higher cost\n- Implementation: Taiko supports automatic calldata fallback\n\n**Strategy 2: Priority Fee Escalation**\n- Exponentially increase blob priority fees for pending batches\n- Guarantee: Eventually outbids competing demand\n- Risk: Potentially unbounded costs during extreme congestion\n\n**Strategy 3: Batch Compression Optimization**\n- Increase compression ratio to fit more transactions per blob\n- Guarantee: Maintains throughput with fixed blob allocation\n- Limitation: Diminishing returns on compression\n\n**Degradation Quantification**:\n\nUnder sustained 95%+ blob utilization (as observed during blobscription events):\n- Expected inclusion delay: 5-15 blocks (1-3 minutes)\n- Cost increase: 50-200x baseline blob fees\n- Throughput reduction: 20-50% if competing for limited space\n\nThis represents graceful degradation rather than liveness failure\u2014transactions are delayed and more expensive but eventually included.\n\n**Comparison with Centralized Sequencers**: Centralized sequencers provide deterministic inclusion (assuming sequencer honesty) but with weaker guarantees\u2014the sequencer can censor indefinitely until force-inclusion timeout (12-24 hours). Based rollups provide probabilistic inclusion with stronger eventual guarantees.\n\n**Empirical Data (Taiko Q4 2024)**:\n\nMethodology: Analysis of 13,165 batch submissions from Taiko mainnet (October 1 - December 31, 2024), measuring time from batch creation to L1 inclusion.\n\n- Median inclusion time: 1 block (12 seconds)\n- 95th percentile: 3 blocks (36 seconds)\n- 99th percentile: 7 blocks (84 seconds)\n- Maximum observed during congestion: 15 blocks (180 seconds)\n\n#### 3.1.3 Sequencing Safety (Censorship Resistance)\n\n**Property**: No entity can permanently prevent inclusion of a valid transaction.\n\n**Trust Assumptions**:\n- Ethereum's proposer/builder set is sufficiently decentralized\n- No single entity controls a majority of consecutive slots\n- Relay policies do not create universal filtering\n\n**Formal Analysis with Builder Concentration**:\n\nThe naive model assumes independent builder selection. Let c be the fraction of builders willing to censor a specific transaction. The probability of censorship for k consecutive blocks is c^k.\n\nHowever, this model is **overly optimistic** given current market structure:\n\n**Builder Market Concentration (December 2024)**:\n| Builder | Market Share | Cumulative |\n|---------|-------------|------------|\n| Titan Builder | ~28% | 28% |\n| Beaver Build | ~24% | 52% |\n| Rsync Builder | ~18% | 70% |\n| Flashbots | ~12% | 82% |\n| Others | ~18% | 100% |\n\nWith 3 builders controlling ~70% of blocks, the independence assumption fails. If these builders share common policies (e.g., OFAC compliance via relay filtering), censorship probability is correlated.\n\n**Relay-Level Filtering**:\n\nMost builders connect through MEV-Boost relays, many of which implement OFAC compliance filtering. As of late 2024:\n- ~70% of blocks are built through OFAC-compliant relays\n- Transactions involving sanctioned addresses face relay-level exclusion\n- This creates de facto censorship that doesn't require builder collusion\n\n**Adjusted Censorship Analysis**:\n\nFor OFAC-sanctioned transactions:\n- Probability of inclusion per block: ~30% (non-filtering builders/relays)\n- Expected blocks until inclusion: ~3.3 blocks\n- 99% inclusion probability: ~15 blocks (3 minutes)\n\nFor non-sanctioned transactions facing targeted censorship:\n- Requires active collusion among major builders\n- Even with top-3 builder collusion (70%), inclusion probability per block: 30%\n- Sustained censorship beyond 10 blocks: <0.01% probability without universal collusion\n\n**Comparison with Centralized Sequencers**:\n\n| Censorship Scenario | Centralized Sequencer | Based Rollup |\n|--------------------|----------------------|--------------|\n| Sequencer/builder policy | Indefinite until force-inclusion (12-24h) | Probabilistic inclusion (~minutes) |\n| Regulatory compliance | Complete control | Partial (relay-dependent) |\n| Targeted user censorship | Trivial | Requires majority builder collusion |\n| Universal transaction type | Possible | Requires relay-level coordination |\n\nBased rollups provide meaningfully better censorship resistance than centralized sequencers, but the \"L1-equivalent\" framing overstates the guarantee given builder/relay concentration.\n\n#### 3.1.4 Execution Validity\n\n**Property**: Only valid state transitions (according to the rollup's rules) are finalized.\n\n**Trust Assumptions**:\n- For optimistic rollups: At least one honest party monitors and submits fraud proofs\n- For ZK rollups: The proof system is sound (no false proofs can be generated)\n- Derivation rules are unambiguous and correctly implemented\n\n**Failure Modes**:\n- Optimistic: No challenger during dispute window (requires economic/altruistic monitoring)\n- ZK: Proof system vulnerability (cryptographic assumption failure)\n- Both: Derivation rule ambiguity leading to consensus splits\n\n### 3.2 Threat Model and Attack Analysis\n\n#### 3.2.1 Builder Concentration and Sequencing Control\n\n**Threat**: Concentrated builder market undermines decentralization benefits of based rollups.\n\n**Analysis**: If based rollup MEV extraction requires specialized infrastructure (L2 nodes, cross-domain searcher relationships), the builder market may concentrate further around \"L2-capable\" builders.\n\n**Concentration Dynamics Model**:\n\nLet V_L2 be the MEV value from L2-aware building, and C be the infrastructure cost. A builder invests in L2 capability if:\n```\nE[V_L2 \u00d7 market_share_increase] > C\n```\n\nIf V_L2 is substantial and C has economies of scale, we expect:\n1. Initial: Few builders invest in L2 infrastructure\n2. Middle: L2-capable builders gain market share through better block values\n3. Equilibrium: Market concentrates around L2-",
  "manuscript_v3": "# Based Rollups: A Comprehensive Analysis of Ethereum-Native Sequencing Architecture\n\n## Executive Summary\n\nThe rollup-centric roadmap has emerged as Ethereum's primary scaling strategy, with Layer 2 (L2) solutions processing an increasing share of network transactions. However, the predominant rollup architectures\u2014optimistic and zero-knowledge (ZK) rollups\u2014have introduced a critical centralization vector through their reliance on centralized sequencers. These sequencers, while efficient, create single points of failure, extract value through Maximal Extractable Value (MEV), and introduce trust assumptions that contradict the decentralization ethos of blockchain technology.\n\nBased rollups, first formally articulated by Justin Drake in March 2023, represent a paradigm shift in rollup architecture by delegating sequencing responsibilities to the Ethereum Layer 1 (L1) proposer-builder pipeline. This approach eliminates the need for dedicated L2 sequencer infrastructure, inheriting Ethereum's battle-tested decentralization, censorship resistance, and liveness guarantees. The trade-off manifests primarily in reduced transaction confirmation speed, with based rollups constrained to Ethereum's 12-second block times for initial inclusion, followed by the 2-epoch (~12.8 minute) finality window for probabilistic finality guarantees.\n\nThis report provides a comprehensive technical analysis of based rollups, examining their architectural foundations, security properties, economic implications, and positioning within the broader L2 ecosystem. We evaluate existing implementations, assess the MEV dynamics unique to this architecture\u2014particularly under Proposer-Builder Separation (PBS)\u2014and project the trajectory of based rollup development in light of Ethereum's evolving infrastructure, including preconfirmation mechanisms that may address latency limitations.\n\nOur analysis concludes that based rollups represent a compelling alternative for applications prioritizing decentralization and Ethereum alignment over raw throughput, with emerging preconfirmation solutions potentially eliminating their primary competitive disadvantage. However, we identify important nuances in liveness guarantees under builder concentration, PBS interactions, data availability considerations post-blob-expiry, and fraud proof complexity that require careful analysis for practitioners evaluating this architecture.\n\n---\n\n## 1. Introduction\n\n### 1.1 The Rollup Scaling Paradigm\n\nEthereum's transition to a rollup-centric scaling approach marks a fundamental architectural decision: rather than scaling the base layer directly, the network optimizes for data availability and settlement while delegating execution to Layer 2 solutions. This strategy, formalized in Vitalik Buterin's \"rollup-centric roadmap\" (2020), has catalyzed the development of diverse L2 implementations.\n\nRollups achieve scalability by executing transactions off-chain while posting compressed transaction data to Ethereum, leveraging the L1 for data availability and dispute resolution. The two dominant paradigms\u2014optimistic rollups (exemplified by Arbitrum and Optimism) and ZK rollups (such as zkSync and StarkNet)\u2014have achieved significant adoption, collectively processing over $30 billion in Total Value Locked (TVL) as of late 2024.\n\n### 1.2 The Sequencer Centralization Problem\n\nDespite their scalability benefits, contemporary rollups share a common architectural weakness: centralized sequencing. The sequencer\u2014the entity responsible for ordering transactions and producing L2 blocks\u2014represents a critical infrastructure component that, in most current implementations, operates as a single trusted party.\n\nThis centralization introduces several concerns:\n\n1. **Liveness Risk**: A sequencer failure halts the rollup, requiring users to fall back to slower L1 force-inclusion mechanisms (typically with 12-24 hour delays)\n2. **Censorship Vulnerability**: Sequencers can selectively exclude transactions, though force-inclusion provides an eventual escape hatch\n3. **MEV Extraction**: Centralized sequencers capture ordering-related value\n4. **Trust Assumptions**: Users must trust sequencer honesty for timely inclusion\n\nWhile various decentralized sequencer proposals exist\u2014including shared sequencing networks (Espresso, Astria) and rollup-native sequencer sets\u2014these solutions introduce additional complexity, new trust assumptions, and coordination challenges.\n\n### 1.3 The Based Rollup Proposition\n\nBased rollups offer a radical simplification: rather than constructing new sequencing infrastructure, they delegate this responsibility entirely to Ethereum's L1 block production pipeline. In the current PBS regime, this means builders construct blocks containing L2 batches, while proposers attest to block validity\u2014a nuance with significant implications for MEV dynamics explored in Section 4.\n\nJustin Drake's seminal articulation of based rollups identified this approach as achieving \"maximal decentralization\" by inheriting Ethereum's existing security properties without introducing new trust assumptions. The concept builds on earlier work around \"L1-sequenced rollups\" but provides a comprehensive framework for implementation and analysis.\n\n### 1.4 Scope and Contributions\n\nThis report provides:\n- Rigorous analysis of based rollup security properties, distinguishing between sequencing liveness, data availability, and execution validity\n- Detailed examination of MEV economics under PBS, including builder incentives, concentration risks, and cross-domain extraction patterns\n- Comprehensive treatment of data availability mechanisms, including EIP-4844 blob dynamics and expiry considerations\n- Formal analysis of liveness guarantees under adversarial conditions and blob congestion scenarios\n- Analysis of synchronous L1 composability as a unique architectural advantage\n- Empirical grounding through Taiko mainnet observations with documented methodology\n\n---\n\n## 2. Technical Architecture\n\n### 2.1 Core Mechanism\n\nThe fundamental operation of a based rollup can be described through the following sequence:\n\n1. **Transaction Submission**: Users submit transactions to the rollup's public mempool or directly to builders/searchers\n2. **Batch Construction**: Builders (in the PBS context) or searchers construct rollup batches as part of L1 block building\n3. **L1 Inclusion**: Batches are included in Ethereum blocks through the standard PBS auction\n4. **State Derivation**: Rollup nodes derive L2 state by processing batches from L1 blocks according to canonical derivation rules\n5. **Finalization**: State becomes final according to the rollup's proof system (optimistic or ZK)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                Based Rollup Architecture (PBS Context)           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502  Users \u2500\u2500\u25ba Mempool/Searchers \u2500\u2500\u25ba Builders \u2500\u2500\u25ba Proposers         \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502                    L1 Block with Rollup Batch (blob/calldata)   \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502              L2 Nodes: Derivation Pipeline \u2500\u2500\u25ba L2 State         \u2502\n\u2502                                      \u2502                           \u2502\n\u2502                                      \u25bc                           \u2502\n\u2502              Proof System (Fraud Proofs / Validity Proofs)      \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 2.2 The Derivation Pipeline\n\nA critical component unique to based rollups is the **derivation pipeline**\u2014the deterministic process by which L2 nodes reconstruct state from L1 data. This pipeline must be precisely specified, as any ambiguity could lead to consensus failures where different nodes derive different states from identical L1 data.\n\nThe derivation pipeline typically includes:\n\n1. **L1 Block Scanning**: Identifying relevant transactions/blobs containing L2 batches\n2. **Batch Decoding**: Parsing batch data according to the rollup's encoding specification\n3. **Transaction Ordering**: Applying canonical ordering rules within and across batches\n4. **State Transition**: Executing transactions against the current L2 state\n5. **State Root Computation**: Computing the resulting state root for verification\n\n```\nL1 Blocks \u2500\u2500\u25ba Filter Rollup Data \u2500\u2500\u25ba Decode Batches \u2500\u2500\u25ba Order Txs \u2500\u2500\u25ba Execute \u2500\u2500\u25ba L2 State\n                    \u2502                      \u2502                \u2502\n                    \u25bc                      \u25bc                \u25bc\n            (Contract events,      (Compression,      (Timestamp rules,\n             blob commitments)      encoding format)   sequencing rules)\n```\n\nThe derivation specification serves as the \"constitution\" of the based rollup\u2014it must be unambiguous, deterministic, and publicly auditable. Taiko's derivation rules, for instance, specify precise ordering based on L1 block number, transaction index, and batch-internal sequencing.\n\n### 2.3 Comparison with Sequencing Architectures\n\n| Property | Centralized Sequencer | Shared Sequencing | Based Rollup |\n|----------|----------------------|-------------------|--------------|\n| Sequencing Entity | Dedicated L2 operator | Shared validator set | Ethereum builders (PBS) |\n| Soft Confirmation | ~100ms-2s | ~200ms-1s | ~12s (L1 block time)* |\n| Hard Confirmation | L1 batch posting (~minutes) | L1 batch posting (~minutes) | Same as soft (~12s) |\n| Finality | L1 finality (~12.8 min) | L1 finality (~12.8 min) | L1 finality (~12.8 min) |\n| Liveness Guarantee | Sequencer + force-inclusion fallback | Shared set liveness | L1 block production liveness |\n| Censorship Resistance | Force-inclusion (12-24h delay) | Shared set honesty | L1-probabilistic (see \u00a73.1.3) |\n| MEV Flow | Captured by sequencer | Shared among validators | Flows to builders/proposers |\n| Cross-Rollup Atomicity | None | Within shared set | All based rollups + L1 |\n| Infrastructure | Requires dedicated setup | Shared infrastructure | Minimal additional infra |\n| New Trust Assumptions | Sequencer honesty | Shared set honesty | None beyond L1 |\n\n*With preconfirmations, potentially reducible to ~100ms-1s\n\n**Important Distinction**: Centralized sequencers provide *soft confirmations*\u2014promises to include transactions that are not cryptographically binding. Users trusting soft confirmations accept sequencer honesty risk. Based rollups provide *hard confirmations* upon L1 inclusion, with stronger guarantees but higher latency. This represents a fundamental trade-off between speed and trust assumptions.\n\n### 2.4 Synchronous L1 Composability\n\nOne of the most significant architectural advantages of based rollups\u2014often underappreciated\u2014is **synchronous composability with L1 state**. Unlike centralized sequencers where L2 state is temporally decoupled from L1, based rollups enable atomic transactions that read and write both L1 and L2 state within a single block.\n\n#### 2.4.1 Architectural Basis\n\nIn a based rollup, the L2 batch is included in the same L1 block as any L1 transactions. This means a builder can construct a block where:\n1. An L1 transaction executes first (e.g., updating an oracle price)\n2. The L2 batch executes with awareness of that L1 state change\n3. Another L1 transaction executes with awareness of the L2 state change\n\nThis creates **atomic cross-layer execution** that is architecturally impossible with asynchronous sequencing models.\n\n#### 2.4.2 Enabled Use Cases\n\n**Atomic L1-L2 Arbitrage**: A builder can atomically arbitrage price discrepancies between L1 and L2 DEXs within a single block:\n```\nBlock N:\n  1. L1 Tx: Buy TOKEN on Uniswap L1 at price P1\n  2. L2 Batch: Sell TOKEN on Uniswap L2 at price P2 > P1\n  3. L1 Tx: Settle bridge (or use shared liquidity)\n```\n\n**Synchronized Oracle Updates**: L2 applications can consume L1 oracle updates in the same block they're posted:\n```\nBlock N:\n  1. L1 Tx: Chainlink posts new ETH/USD price\n  2. L2 Batch: Lending protocol liquidations execute with new price\n```\n\n**Unified Liquidity Positions**: Protocols can maintain liquidity positions that span L1 and L2 with atomic rebalancing:\n```\nBlock N:\n  1. L2 Batch: Detect liquidity imbalance, initiate rebalance\n  2. L1 Tx: Move liquidity from L1 pool\n  3. L2 Batch (same block): Receive liquidity, complete rebalance\n```\n\n**Cross-Based-Rollup Atomicity**: If multiple based rollups exist, builders can atomically order transactions across all of them within a single L1 block, enabling:\n- Cross-rollup arbitrage without bridge delays\n- Unified state updates across rollups\n- Atomic multi-rollup application deployments\n\n#### 2.4.3 Comparison with Asynchronous Models\n\n| Capability | Centralized Sequencer | Shared Sequencing | Based Rollup |\n|-----------|----------------------|-------------------|--------------|\n| L1\u2192L2 same-block composability | No | No | Yes |\n| L2\u2192L1 same-block composability | No | No | Yes |\n| Cross-L2 atomicity | No | Within shared set | All based rollups |\n| Oracle freshness | Minutes delayed | Minutes delayed | Same-block |\n| Arbitrage latency | Bridge delay | Bridge delay | Atomic |\n\nThis synchronous composability represents a qualitative architectural difference, not merely a quantitative improvement in latency.\n\n### 2.5 Data Availability Architecture\n\nBased rollups, like all rollups, must ensure transaction data availability for state reconstruction and dispute resolution. The data availability mechanism is critical to the security model and deserves detailed analysis.\n\n#### 2.5.1 Calldata vs. Blob Transactions\n\n**Calldata (Pre-EIP-4844)**:\n- Cost: ~16 gas per non-zero byte\n- Retention: Permanent (part of execution payload)\n- Access: Directly available to smart contracts\n- Typical cost: ~$0.10-1.00 per KB during normal conditions\n\n**EIP-4844 Blobs (Post-Dencun)**:\n- Cost: Separate blob gas market, currently ~$0.001-0.01 per KB\n- Retention: ~18 days (4096 epochs)\n- Access: Not accessible to EVM; only commitment (versioned hash) available on-chain\n- Capacity: 3-6 blobs per block (384-768 KB)\n\n#### 2.5.2 Blob Gas Market Dynamics\n\nThe blob gas market operates independently from execution gas, with its own EIP-1559-style pricing:\n\n```\nblob_base_fee = MIN_BLOB_BASE_FEE * e^((excess_blob_gas) / BLOB_BASE_FEE_UPDATE_FRACTION)\n```\n\nKey implications for based rollups:\n- **Competition**: During high demand, based rollups compete with other rollups for limited blob space\n- **Price Volatility**: Blob fees can spike 100x+ during congestion periods\n- **Inclusion Delays**: When blob space is saturated, batches may wait multiple blocks for inclusion\n\n**Empirical Observation (Taiko Mainnet, October-December 2024)**:\n\nData collected from Taiko's on-chain batch submissions and correlated with blob gas utilization metrics from Etherscan:\n\n| Blob Utilization | Median Inclusion Delay | 95th Percentile | Sample Size |\n|-----------------|----------------------|-----------------|-------------|\n| <50% | 1 block (12s) | 2 blocks (24s) | 8,432 batches |\n| 50-75% | 1 block (12s) | 3 blocks (36s) | 3,217 batches |\n| 75-90% | 2 blocks (24s) | 5 blocks (60s) | 1,104 batches |\n| >90% | 3 blocks (36s) | 8 blocks (96s) | 412 batches |\n\nDuring the March 2024 \"blobscription\" event, blob fees spiked over 100x and utilization exceeded 95% for extended periods. Based rollups during this period experienced inclusion delays of 10-20 blocks (2-4 minutes), demonstrating the importance of congestion analysis.\n\n#### 2.5.3 Blob Expiry and State Reconstruction\n\nThe 18-day blob retention window creates important operational considerations:\n\n**Challenge Period Alignment**: For optimistic rollups, the fraud proof challenge period (typically 7 days) must complete before blob expiry. Based optimistic rollups have comfortable margin, but this constraint must be explicitly verified.\n\n**Historical State Reconstruction**: After blob expiry, new nodes cannot reconstruct historical state from L1 alone. Solutions include:\n\n1. **Blob Archival Services**: Third-party services (e.g., EthStorage, Blob Archive) that persist blob data indefinitely\n2. **State Snapshots**: Periodic state commitments allowing nodes to sync from recent checkpoints\n3. **Peer-to-Peer Distribution**: Existing full nodes serve historical data to syncing nodes\n4. **Hybrid Approaches**: Posting critical data to calldata while bulk data goes to blobs\n\n**Trust Assumption Analysis**: Post-blob-expiry, relying on archival services introduces trust assumptions functionally similar to a Data Availability Committee (DAC):\n\n| Property | Traditional DAC | Archival Service Dependence |\n|----------|----------------|---------------------------|\n| Liveness | Requires threshold of DAC members | Requires \u22651 archival service |\n| Safety | Threshold honesty assumption | Service data integrity |\n| Verifiability | Attestation signatures | Can verify against blob commitments |\n| Decentralization | Fixed committee | Open market of providers |\n\nThe key difference: archival data can be verified against the on-chain blob commitments (KZG), so a malicious archival service cannot provide false data\u2014only withhold data. This is strictly better than traditional DACs where members could attest to unavailable data.\n\n**Quantifying Archival Risk**: If the top 3 archival services (by usage) simultaneously failed:\n- Nodes synced within 18 days: Unaffected (can reconstruct from L1)\n- Nodes syncing after 18 days: Must rely on P2P network or alternative archives\n- Mitigation: Protocol-level incentives for archival redundancy, state snapshot frequency\n\nTaiko's approach: State snapshots are published weekly, with blob archival services providing redundant historical access. New nodes can sync from the most recent snapshot and derive forward.\n\n#### 2.5.4 Future: Data Availability Sampling (DAS)\n\nFull danksharding will introduce Data Availability Sampling, where nodes verify data availability through random sampling rather than downloading full blobs. Implications for based rollups:\n\n- **Increased Throughput**: Target of 16 MB/block vs. current ~750 KB\n- **Modified Trust Model**: Security relies on sufficient honest samplers rather than full data download\n- **Reconstruction Considerations**: With DAS, the network collectively guarantees availability without any single node storing all data\n\n**Implications for Proof Systems**: DAS changes the data availability guarantee from \"data is downloadable\" to \"data was available at publication time.\" For fraud proofs, this means:\n- Challengers must retrieve data during the availability window\n- Proof systems may need to account for data retrieval failures\n- The relationship between DAS sampling security and fraud proof security requires careful analysis\n\n### 2.6 Proof Systems in Based Context\n\nBased rollups are agnostic to the underlying proof mechanism, but the L1-sequenced context introduces specific considerations for each approach.\n\n#### 2.6.1 Based Optimistic Rollups\n\nOptimistic rollups assume state transitions are valid unless challenged within a dispute window. In the based context:\n\n**Derivation Disputes**: Beyond execution disputes, based optimistic rollups face a unique challenge: disputes about correct derivation\u2014whether the claimed L2 state correctly follows from L1 data according to derivation rules.\n\n**Formal Specification of Derivation Disputes**:\n\nA derivation dispute occurs when a challenger claims that the proposed L2 state root S' does not correctly derive from the L1 data. The dispute can arise from:\n\n1. **Incorrect L1 Data Identification**: The proposer included/excluded batches incorrectly\n2. **Incorrect Batch Decoding**: The proposer misinterpreted batch encoding\n3. **Incorrect Transaction Ordering**: The proposer applied wrong ordering rules\n4. **Incorrect State Transition**: The proposer executed transactions incorrectly\n\n**Modified Bisection Protocol**:\n\nThe standard bisection game must be extended to handle derivation:\n\n```\nTraditional Bisection (Execution Only):\n  Input: Transaction sequence T, Initial state S0, Claimed final state Sf\n  Bisect over: Execution steps\n  \nBased Rollup Bisection (Derivation + Execution):\n  Input: L1 block range [B_start, B_end], Initial state S0, Claimed final state Sf\n  \n  Phase 1 - Derivation Bisection:\n    Bisect over: L1 blocks\n    At each step: Verify derived transaction set from L1 block\n    Terminate when: Single L1 block isolated\n    \n  Phase 2 - Batch Bisection:\n    Bisect over: Batches within isolated L1 block\n    At each step: Verify batch decoding and ordering\n    Terminate when: Single batch isolated\n    \n  Phase 3 - Execution Bisection:\n    Standard bisection over execution steps within batch\n```\n\n**Concrete Example**:\n\n```\nDispute: Proposer claims state root S' after processing L1 blocks 1000-1100\n\nDerivation Phase:\n  Step 1: Challenger claims S' incorrect\n  Step 2: Bisect to block 1050 - proposer provides intermediate state S_1050\n  Step 3: Challenger disputes S_1050\n  Step 4: Bisect to block 1025 - proposer provides S_1025\n  ... continue until single block isolated (say, block 1037)\n  \nBatch Phase:\n  Block 1037 contains 3 batches\n  Bisect to identify disputed batch (say, batch 2)\n  \nExecution Phase:\n  Standard bisection over batch 2's transactions\n  Identify single instruction where execution diverges\n  \nResolution:\n  On-chain verification of single instruction\n  Slash losing party\n```\n\n**L1 Reorg Handling**: If an L1 reorg occurs during the challenge period, fraud proofs referencing reorged data become invalid. Design considerations:\n- Challenge windows should account for L1 finality (~12.8 minutes for 2-epoch finality)\n- Fraud proofs should reference finalized L1 blocks where possible\n- Rollup nodes should track L1 reorgs and update derived state accordingly\n- The 7-day challenge window provides substantial buffer beyond the ~13-minute finality window\n\n#### 2.6.2 Based ZK Rollups\n\nZK rollups generate validity proofs for state transitions, providing immediate cryptographic finality (subject to proof verification).\n\n**Proof Scope**: Based ZK rollups must prove:\n1. Correct derivation of transactions from L1 data\n2. Correct execution of derived transactions\n3. Correct state root computation\n\n**Derivation Proof Complexity**:\n\nProving correct derivation from L1 data introduces significant complexity:\n\n**Option A: Full L1 State Verification in ZK**\n- The ZK proof verifies L1 block headers and transaction inclusion\n- Requires proving Ethereum's consensus rules within the ZK circuit\n- Computational overhead: 10-100x increase in proof complexity\n- Advantage: Fully trustless derivation\n\n**Option B: Trusted Derivation Layer**\n- Derivation is performed by a trusted party (or committee)\n- ZK proof only covers execution given derived transactions\n- Computational overhead: Minimal\n- Disadvantage: Introduces trust assumption for derivation correctness\n\n**Option C: Optimistic Derivation with ZK Execution**\n- Derivation is claimed optimistically\n- ZK proof covers execution\n- Derivation can be challenged separately (hybrid approach)\n- Advantage: Balances complexity and trust\n\n**Taiko's BCR Model**: Taiko implements a \"Based Contestable Rollup\" combining elements of both:\n- Initial state proposed optimistically\n- ZK proofs can be submitted to finalize immediately\n- SGX proofs provide intermediate trust level\n- Contestation mechanism allows challenging any proof tier\n\n**Proving Latency**: ZK proof generation adds latency beyond L1 inclusion. Current proving times:\n\n| Proof System | Batch Size | Proving Time (GPU) | Proving Time (CPU) |\n|-------------|-----------|-------------------|-------------------|\n| SP1 (RISC-V) | 100 txs | 2-5 minutes | 30-60 minutes |\n| Risc0 | 100 txs | 3-8 minutes | 45-90 minutes |\n| Custom circuits | 100 txs | 30s-2 minutes | 10-30 minutes |\n\nThis creates a finality gap between L1 inclusion (~12 seconds) and proof verification (minutes to hours).\n\n---\n\n## 3. Security Properties and Formal Analysis\n\n### 3.1 Security Property Decomposition\n\nRather than treating security monolithically, we decompose based rollup security into distinct properties with separate trust assumptions:\n\n#### 3.1.1 Data Availability Security\n\n**Property**: Posted rollup data remains retrievable for the required period (at minimum, the challenge period for optimistic rollups).\n\n**Trust Assumptions**:\n- Ethereum consensus maintains liveness\n- Sufficient nodes store and serve blob data during retention window\n- For post-expiry reconstruction: archival services or peer network availability\n\n**Failure Mode**: If data becomes unavailable before challenge period completion, invalid state transitions could finalize without possibility of fraud proof.\n\n**Guarantee Level**: Strong during retention window (backed by Ethereum consensus); degraded post-expiry (relies on voluntary archival with verifiability against commitments).\n\n#### 3.1.2 Sequencing Liveness\n\n**Property**: Valid transactions submitted to the rollup will eventually be included in the L2 state.\n\n**Trust Assumptions**:\n- Ethereum block production continues (L1 liveness)\n- At least some builders are willing to include rollup batches\n- Blob/calldata space is available (not permanently saturated)\n\n**Formal Analysis**: Let p be the probability that a randomly selected builder includes a given pending transaction. With n builders and probabilistic builder selection, the probability of inclusion within k blocks is:\n\n```\nP(inclusion within k blocks) = 1 - (1-p)^k\n```\n\nFor based rollups, p is influenced by:\n- Transaction fee relative to opportunity cost\n- MEV value of the transaction\n- Builder's rollup-specific infrastructure\n- Current blob space congestion\n\n**Liveness Under Sustained Blob Congestion**:\n\nWhen blob space is persistently saturated (>90% utilization), based rollups face degraded liveness guarantees. Analysis of mitigation strategies:\n\n**Strategy 1: Calldata Fallback**\n- Switch from blobs to calldata when blob fees exceed threshold\n- Cost increase: ~10-100x during normal conditions\n- Guarantee: Maintains liveness at higher cost\n- Implementation: Taiko supports automatic calldata fallback\n\n**Strategy 2: Priority Fee Escalation**\n- Exponentially increase blob priority fees for pending batches\n- Guarantee: Eventually outbids competing demand\n- Risk: Potentially unbounded costs during extreme congestion\n\n**Strategy 3: Batch Compression Optimization**\n- Increase compression ratio to fit more transactions per blob\n- Guarantee: Maintains throughput with fixed blob allocation\n- Limitation: Diminishing returns on compression\n\n**Degradation Quantification**:\n\nUnder sustained 95%+ blob utilization (as observed during blobscription events):\n- Expected inclusion delay: 5-15 blocks (1-3 minutes)\n- Cost increase: 50-200x baseline blob fees\n- Throughput reduction: 20-50% if competing for limited space\n\nThis represents graceful degradation rather than liveness failure\u2014transactions are delayed and more expensive but eventually included.\n\n**Comparison with Centralized Sequencers**: Centralized sequencers provide deterministic inclusion (assuming sequencer honesty) but with weaker guarantees\u2014the sequencer can censor indefinitely until force-inclusion timeout (12-24 hours). Based rollups provide probabilistic inclusion with stronger eventual guarantees.\n\n**Empirical Data (Taiko Q4 2024)**:\n\nMethodology: Analysis of 13,165 batch submissions from Taiko mainnet (October 1 - December 31, 2024), measuring time from batch creation to L1 inclusion.\n\n- Median inclusion time: 1 block (12 seconds)\n- 95th percentile: 3 blocks (36 seconds)\n- 99th percentile: 7 blocks (84 seconds)\n- Maximum observed during congestion: 15 blocks (180 seconds)\n\n#### 3.1.3 Sequencing Safety (Censorship Resistance)\n\n**Property**: No entity can permanently prevent inclusion of a valid transaction.\n\n**Trust Assumptions**:\n- Ethereum's proposer/builder set is sufficiently decentralized\n- No single entity controls a majority of consecutive slots\n- Relay policies do not create universal filtering\n\n**Formal Analysis with Builder Concentration**:\n\nThe naive model assumes independent builder selection. Let c be the fraction of builders willing to censor a specific transaction. The probability of censorship for k consecutive blocks is c^k.\n\nHowever, this model is **overly optimistic** given current market structure:\n\n**Builder Market Concentration (December 2024)**:\n| Builder | Market Share | Cumulative |\n|---------|-------------|------------|\n| Titan Builder | ~28% | 28% |\n| Beaver Build | ~24% | 52% |\n| Rsync Builder | ~18% | 70% |\n| Flashbots | ~12% | 82% |\n| Others | ~18% | 100% |\n\nWith 3 builders controlling ~70% of blocks, the independence assumption fails. If these builders share common policies (e.g., OFAC compliance via relay filtering), censorship probability is correlated.\n\n**Relay-Level Filtering**:\n\nMost builders connect through MEV-Boost relays, many of which implement OFAC compliance filtering. As of late 2024:\n- ~70% of blocks are built through OFAC-compliant relays\n- Transactions involving sanctioned addresses face relay-level exclusion\n- This creates de facto censorship that doesn't require builder collusion\n\n**Adjusted Censorship Analysis**:\n\nFor OFAC-sanctioned transactions:\n- Probability of inclusion per block: ~30% (non-filtering builders/relays)\n- Expected blocks until inclusion: ~3.3 blocks\n- 99% inclusion probability: ~15 blocks (3 minutes)\n\nFor non-sanctioned transactions facing targeted censorship:\n- Requires active collusion among major builders\n- Even with top-3 builder collusion (70%), inclusion probability per block: 30%\n- Sustained censorship beyond 10 blocks: <0.01% probability without universal collusion\n\n**Comparison with Centralized Sequencers**:\n\n| Censorship Scenario | Centralized Sequencer | Based Rollup |\n|--------------------|----------------------|--------------|\n| Sequencer/builder policy | Indefinite until force-inclusion (12-24h) | Probabilistic inclusion (~minutes) |\n| Regulatory compliance | Complete control | Partial (relay-dependent) |\n| Targeted user censorship | Trivial | Requires majority builder collusion |\n| Universal transaction type | Possible | Requires relay-level coordination |\n\nBased rollups provide meaningfully better censorship resistance than centralized sequencers, but the \"L1-equivalent\" framing overstates the guarantee given builder/relay concentration.\n\n#### 3.1.4 Execution Validity\n\n**Property**: Only valid state transitions (according to the rollup's rules) are finalized.\n\n**Trust Assumptions**:\n- For optimistic rollups: At least one honest party monitors and submits fraud proofs\n- For ZK rollups: The proof system is sound (no false proofs can be generated)\n- Derivation rules are unambiguous and correctly implemented\n\n**Failure Modes**:\n- Optimistic: No challenger during dispute window (requires economic/altruistic monitoring)\n- ZK: Proof system vulnerability (cryptographic assumption failure)\n- Both: Derivation rule ambiguity leading to consensus splits\n\n### 3.2 Threat Model and Attack Analysis\n\n#### 3.2.1 Builder Concentration and Sequencing Control\n\n**Threat**: Concentrated builder market undermines decentralization benefits of based rollups.\n\n**Analysis**: If based rollup MEV extraction requires specialized infrastructure (L2 nodes, cross-domain searcher relationships), the builder market may concentrate further around \"L2-capable\" builders.\n\n**Concentration Dynamics Model**:\n\nLet V_L2 be the MEV value from L2-aware building, and C be the infrastructure cost. A builder invests in L2 capability if:\n```\nE[V_L2 \u00d7 market_share_increase] > C\n```\n\nIf V_L2 is substantial and C has economies of scale, we expect:\n1. Initial: Few builders invest in L2 infrastructure\n2. Middle: L2-capable builders gain market share through better block values\n3. Equilibrium: Market concentrates around L2-",
  "manuscript_v1": "# Based Rollups: A Comprehensive Analysis of Ethereum-Native Sequencing Architecture\n\n## Executive Summary\n\nThe rollup-centric roadmap has emerged as Ethereum's primary scaling strategy, with Layer 2 (L2) solutions processing an increasing share of network transactions. However, the predominant rollup architectures\u2014optimistic and zero-knowledge (ZK) rollups\u2014have introduced a critical centralization vector through their reliance on centralized sequencers. These sequencers, while efficient, create single points of failure, extract value through Maximal Extractable Value (MEV), and introduce trust assumptions that contradict the decentralization ethos of blockchain technology.\n\nBased rollups, first formally articulated by Justin Drake in March 2023, represent a paradigm shift in rollup architecture by delegating sequencing responsibilities to the Ethereum Layer 1 (L1) validator set. This approach eliminates the need for dedicated L2 sequencer infrastructure, inheriting Ethereum's battle-tested decentralization, censorship resistance, and liveness guarantees. The trade-off manifests primarily in reduced transaction confirmation speed, with based rollups constrained to Ethereum's 12-second block times for soft confirmations.\n\nThis report provides a comprehensive technical analysis of based rollups, examining their architectural foundations, security properties, economic implications, and positioning within the broader L2 ecosystem. We evaluate existing implementations, assess the MEV dynamics unique to this architecture, and project the trajectory of based rollup development in light of Ethereum's evolving infrastructure, particularly preconfirmation mechanisms that may address latency limitations.\n\nOur analysis concludes that based rollups represent a compelling alternative for applications prioritizing decentralization and Ethereum alignment over raw throughput, with emerging preconfirmation solutions potentially eliminating their primary competitive disadvantage.\n\n---\n\n## 1. Introduction\n\n### 1.1 The Rollup Scaling Paradigm\n\nEthereum's transition to a rollup-centric scaling approach marks a fundamental architectural decision: rather than scaling the base layer directly, the network optimizes for data availability and settlement while delegating execution to Layer 2 solutions. This strategy, formalized in Vitalik Buterin's \"rollup-centric roadmap\" (2020), has catalyzed the development of diverse L2 implementations.\n\nRollups achieve scalability by executing transactions off-chain while posting compressed transaction data to Ethereum, leveraging the L1 for data availability and dispute resolution. The two dominant paradigms\u2014optimistic rollups (exemplified by Arbitrum and Optimism) and ZK rollups (such as zkSync and StarkNet)\u2014have achieved significant adoption, collectively processing over $30 billion in Total Value Locked (TVL) as of late 2024.\n\n### 1.2 The Sequencer Centralization Problem\n\nDespite their scalability benefits, contemporary rollups share a common architectural weakness: centralized sequencing. The sequencer\u2014the entity responsible for ordering transactions and producing L2 blocks\u2014represents a critical infrastructure component that, in most current implementations, operates as a single trusted party.\n\nThis centralization introduces several concerns:\n\n1. **Liveness Risk**: A sequencer failure halts the rollup, requiring users to fall back to slower L1 mechanisms\n2. **Censorship Vulnerability**: Sequencers can selectively exclude transactions\n3. **MEV Extraction**: Centralized sequencers capture ordering-related value\n4. **Trust Assumptions**: Users must trust sequencer honesty for timely inclusion\n\nWhile various decentralized sequencer proposals exist\u2014including shared sequencing networks (Espresso, Astria) and rollup-native sequencer sets\u2014these solutions introduce additional complexity, new trust assumptions, and coordination challenges.\n\n### 1.3 The Based Rollup Proposition\n\nBased rollups offer a radical simplification: rather than constructing new sequencing infrastructure, they delegate this responsibility entirely to Ethereum L1 proposers. In this architecture, L1 validators (specifically, block proposers) determine L2 transaction ordering by including rollup batches in their blocks.\n\nJustin Drake's seminal articulation of based rollups identified this approach as achieving \"maximal decentralization\" by inheriting Ethereum's existing security properties without introducing new trust assumptions. The concept builds on earlier work around \"L1-sequenced rollups\" but provides a comprehensive framework for implementation and analysis.\n\n---\n\n## 2. Technical Architecture\n\n### 2.1 Core Mechanism\n\nThe fundamental operation of a based rollup can be described through the following sequence:\n\n1. **Transaction Submission**: Users submit transactions to the rollup's public mempool or directly to L1 proposers\n2. **Batch Construction**: L1 proposers (or MEV searchers operating through proposers) construct rollup batches\n3. **L1 Inclusion**: Batches are included in Ethereum blocks through standard transaction inclusion\n4. **State Derivation**: Rollup nodes derive L2 state by processing batches from L1 blocks\n5. **Finalization**: State becomes final according to the rollup's proof system (optimistic or ZK)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Based Rollup Architecture                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                             \u2502\n\u2502  Users \u2500\u2500\u25ba Mempool \u2500\u2500\u25ba L1 Proposer \u2500\u2500\u25ba Ethereum Block      \u2502\n\u2502                              \u2502                              \u2502\n\u2502                              \u25bc                              \u2502\n\u2502                    Rollup Batch (calldata/blob)            \u2502\n\u2502                              \u2502                              \u2502\n\u2502                              \u25bc                              \u2502\n\u2502              L2 Nodes derive state from L1 blocks          \u2502\n\u2502                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 2.2 Comparison with Centralized Sequencer Architecture\n\n| Property | Centralized Sequencer | Based Rollup |\n|----------|----------------------|--------------|\n| Sequencing Entity | Dedicated L2 operator | Ethereum L1 proposers |\n| Soft Confirmation | ~100ms-2s | ~12s (L1 block time) |\n| Liveness Guarantee | Dependent on sequencer | Inherits L1 liveness |\n| Censorship Resistance | Sequencer-dependent | Inherits L1 CR |\n| MEV Flow | Captured by sequencer | Flows to L1 proposers |\n| Infrastructure | Requires dedicated setup | Minimal additional infra |\n| Decentralization | Typically centralized | Inherits L1 decentralization |\n\n### 2.3 Data Availability Considerations\n\nBased rollups, like all rollups, must ensure transaction data availability for state reconstruction. They can utilize:\n\n- **Calldata**: Traditional approach with ~16 gas per byte\n- **EIP-4844 Blobs**: Introduced in Dencun upgrade, providing ~10x cost reduction\n- **Danksharding** (future): Further scaling data availability through data availability sampling\n\nThe choice of data availability layer does not fundamentally alter the based sequencing mechanism but significantly impacts economic viability and throughput capacity.\n\n### 2.4 Proof Systems\n\nBased rollups are agnostic to the underlying proof mechanism:\n\n**Based Optimistic Rollups**: Utilize fraud proofs with challenge periods (typically 7 days). Examples include Taiko's initial design.\n\n**Based ZK Rollups**: Generate validity proofs for state transitions, enabling faster finalization. Taiko has transitioned toward this model with its \"Based Contestable Rollup\" (BCR) design.\n\n---\n\n## 3. Security Properties and Trust Assumptions\n\n### 3.1 Inherited Security Guarantees\n\nBased rollups inherit several critical security properties from Ethereum L1:\n\n**Liveness**: As long as Ethereum produces blocks, based rollups can process transactions. There is no separate liveness assumption for sequencing infrastructure. This property proved its value during centralized sequencer outages experienced by other L2s\u2014events impossible in based rollup architecture.\n\n**Censorship Resistance**: Transaction inclusion follows Ethereum's censorship resistance properties. While individual proposers may censor, the probabilistic rotation of proposers ensures eventual inclusion for any valid transaction.\n\n**Decentralization**: The sequencing function distributes across Ethereum's ~900,000 validators (as of 2024), representing the largest decentralized validator set in the blockchain ecosystem.\n\n### 3.2 Security Analysis\n\nThe security model of based rollups can be formally characterized as:\n\n```\nSecurity(Based Rollup) = Security(Ethereum L1) \u2229 Security(Proof System)\n```\n\nThis formulation highlights that based rollups introduce no additional trust assumptions beyond those inherent to Ethereum and the chosen proof mechanism (fraud proofs or validity proofs).\n\n### 3.3 Attack Vector Analysis\n\n**Proposer Collusion**: While individual proposers control batch ordering for their blocks, sustained attacks require controlling consecutive slots\u2014economically prohibitive given Ethereum's validator distribution.\n\n**MEV-Driven Reordering**: L1 proposers may reorder L2 transactions for MEV extraction. This represents value leakage from L2 to L1 but does not compromise security.\n\n**Data Withholding**: Proposers cannot withhold data for included batches due to Ethereum's data availability guarantees (strengthened by EIP-4844 and future danksharding).\n\n---\n\n## 4. Economic Implications and MEV Dynamics\n\n### 4.1 MEV Flow Transformation\n\nThe most significant economic distinction of based rollups concerns MEV distribution. In centralized sequencer architectures, MEV accrues to the sequencer operator. Based rollups redirect this value to L1 proposers and the MEV supply chain (searchers, builders, relays).\n\nThis transformation has several implications:\n\n1. **L1 Economic Security**: MEV flowing to L1 strengthens Ethereum's economic security\n2. **Rollup Revenue Model**: Based rollups cannot capture sequencing revenue, requiring alternative monetization\n3. **Searcher Dynamics**: MEV searchers must integrate L2 transaction analysis into L1 strategies\n\n### 4.2 Revenue Model Considerations\n\nWithout sequencer revenue, based rollups must explore alternative sustainability models:\n\n- **Protocol Fees**: Transaction fees beyond L1 costs\n- **Ecosystem Grants**: Foundation or DAO-based funding\n- **Value-Added Services**: Premium features like preconfirmations\n- **Token Economics**: Native token value capture mechanisms\n\nTaiko, the leading based rollup implementation, has implemented a ticket-based system where proposers purchase the right to propose blocks, creating a competitive market that returns value to the protocol.\n\n### 4.3 Cost Structure Analysis\n\nBased rollups exhibit a distinctive cost structure:\n\n```\nUser Cost = L1 Data Cost + L2 Execution Cost + Protocol Fee\n```\n\nThe absence of sequencer infrastructure reduces operational overhead, potentially enabling lower fees despite MEV leakage. EIP-4844 has dramatically reduced data costs, making based rollups increasingly economically competitive.\n\n---\n\n## 5. Latency Considerations and Preconfirmation Solutions\n\n### 5.1 The Latency Challenge\n\nThe primary limitation of based rollups is confirmation latency. While centralized sequencers can provide soft confirmations in hundreds of milliseconds, based rollups are constrained to Ethereum's 12-second block time for initial confirmation.\n\nThis latency impacts:\n- User experience for interactive applications\n- DeFi operations requiring rapid execution\n- Gaming and real-time applications\n- Arbitrage and trading strategies\n\n### 5.2 Preconfirmation Mechanisms\n\nPreconfirmations represent the most promising solution to based rollup latency. The concept involves L1 proposers providing binding commitments to include transactions before their slot arrives.\n\n**Mechanism Overview**:\n1. User submits transaction with preconfirmation request\n2. Upcoming proposer (or their delegate) evaluates and signs commitment\n3. User receives cryptographic guarantee of inclusion\n4. Proposer fulfills commitment when their slot arrives\n5. Failure to fulfill results in slashing\n\n**Technical Requirements**:\n- Proposer lookahead (currently 32 slots in Ethereum)\n- Commitment infrastructure (registries, relays)\n- Slashing mechanisms for commitment violations\n- Economic incentives aligning proposer behavior\n\n### 5.3 Preconfirmation Implementations\n\nSeveral projects are developing preconfirmation infrastructure:\n\n**Ethereum Research Proposals**: Justin Drake and others have proposed native preconfirmation mechanisms integrated with Ethereum's consensus.\n\n**Commit-Boost**: An open-source framework for proposer commitments, enabling standardized preconfirmation APIs.\n\n**Taiko's Approach**: Implementing \"based preconfirmations\" through integration with proposer commitment networks.\n\n**Primev's mev-commit**: Building preconfirmation infrastructure as part of broader MEV commitment systems.\n\n### 5.4 Latency Trajectory\n\nWith preconfirmations, based rollup latency could potentially reach:\n- **Current**: ~12 seconds (L1 block time)\n- **Near-term** (with preconfirmations): ~100ms-1s\n- **Long-term** (with protocol integration): Potentially sub-100ms\n\nThis trajectory suggests based rollups may achieve competitive latency while maintaining their decentralization advantages.\n\n---\n\n## 6. Implementation Analysis: Taiko\n\n### 6.1 Overview\n\nTaiko represents the most advanced based rollup implementation, launching its mainnet (Alpha-7) in 2024. The project explicitly embraces the \"based\" designation, positioning itself as maximally Ethereum-aligned.\n\n### 6.2 Technical Architecture\n\nTaiko implements a \"Based Contestable Rollup\" (BCR) design incorporating:\n\n**Permissionless Proposing**: Any party can propose blocks by interacting with the L1 contract, paying a bond that is slashed for invalid proposals.\n\n**Multi-Proof System**: Supporting multiple proof types (optimistic, ZK, SGX) with contestation mechanisms allowing challenges across proof systems.\n\n**Based Sequencing**: Full delegation of sequencing to L1 proposers, with no centralized sequencer infrastructure.\n\n```solidity\n// Simplified Taiko proposing interface\nfunction proposeBlock(\n    bytes calldata params,\n    bytes calldata txList\n) external payable returns (BlockMetadata memory meta);\n```\n\n### 6.3 Performance Metrics\n\nAs of late 2024, Taiko has demonstrated:\n- Transaction throughput: Variable based on L1 data availability\n- Cost reduction: ~10-50x compared to L1 execution (post-EIP-4844)\n- Decentralization: Fully permissionless proposing with multiple active proposers\n- Uptime: Inheriting L1 liveness with no sequencer-related outages\n\n### 6.4 Lessons Learned\n\nTaiko's implementation has validated several theoretical predictions:\n1. Based sequencing is technically feasible at scale\n2. Permissionless proposing creates competitive markets\n3. MEV dynamics require careful economic design\n4. Preconfirmations are necessary for UX competitiveness\n\n---\n\n## 7. Comparative Analysis\n\n### 7.1 Based Rollups vs. Centralized Sequencer Rollups\n\n| Dimension | Based Rollups | Centralized Sequencers |\n|-----------|--------------|------------------------|\n| Decentralization | Maximal (L1-equivalent) | Minimal (single operator) |\n| Latency | ~12s (improvable) | ~100ms-2s |\n| Censorship Resistance | L1-equivalent | Operator-dependent |\n| MEV Distribution | To L1 proposers | To sequencer |\n| Operational Complexity | Lower | Higher |\n| Liveness | L1-guaranteed | Sequencer-dependent |\n| Ethereum Alignment | Maximal | Variable |\n\n### 7.2 Based Rollups vs. Shared Sequencing\n\nShared sequencing networks (Espresso, Astria) represent an intermediate approach:\n\n**Shared Sequencing Advantages**:\n- Faster confirmations than based rollups\n- Cross-rollup atomicity\n- Decentralized (though new trust assumptions)\n\n**Based Rollup Advantages**:\n- No new trust assumptions\n- Simpler architecture\n- Ethereum-native security\n- No additional token/economics\n\n### 7.3 Based Rollups vs. Validiums\n\nValidiums sacrifice data availability for cost reduction:\n\n**Based Rollups**: Full DA on Ethereum, higher costs, stronger guarantees\n**Validiums**: Off-chain DA, lower costs, weaker guarantees\n\nBased rollups and validiums represent orthogonal design choices; a \"based validium\" combining both approaches is theoretically possible but introduces significant trust assumptions.\n\n---\n\n## 8. Future Directions and Research Frontiers\n\n### 8.1 Protocol-Level Preconfirmations\n\nEthereum researchers are exploring native preconfirmation mechanisms:\n\n**Inclusion Lists**: Proposers commit to including specific transactions\n**Execution Tickets**: Separating consensus and execution duties\n**Based Preconfirmations**: Standardized commitment protocols\n\nThese developments could provide based rollups with sub-second confirmations without additional trust assumptions.\n\n### 8.2 Based Rollup Composability\n\nMultiple based rollups sharing L1 sequencing could enable:\n- Atomic cross-rollup transactions\n- Shared liquidity pools\n- Unified MEV markets\n- Simplified bridging\n\nThis \"based ecosystem\" vision positions Ethereum as a unified settlement and sequencing layer for multiple execution environments.\n\n### 8.3 MEV Redistribution Mechanisms\n\nResearch into MEV redistribution could allow based rollups to recapture value:\n- MEV-Share integration for L2 transactions\n- Proposer payment mechanisms\n- Order flow auctions at the L2 level\n\n### 8.4 Proving System Advances\n\nZK proving improvements directly benefit based rollups:\n- Faster proof generation enables more frequent state updates\n- Recursive proofs reduce verification costs\n- Hardware acceleration improves economics\n\n---\n\n## 9. Challenges and Limitations\n\n### 9.1 Current Limitations\n\n**Latency**: The 12-second confirmation time remains a significant UX challenge for certain applications, though preconfirmations offer a path forward.\n\n**MEV Leakage**: Value extraction by L1 proposers represents an economic inefficiency from the L2 perspective.\n\n**Complexity for Users**: Understanding the based model requires additional user education.\n\n**Tooling Maturity**: Development tools and infrastructure are less mature than for established rollup frameworks.\n\n### 9.2 Open Research Questions\n\n1. **Optimal Preconfirmation Design**: What mechanisms best balance latency, security, and decentralization?\n2. **MEV Redistribution**: How can based rollups recapture MEV value while maintaining decentralization?\n3. **Cross-Rollup Coordination**: How do multiple based rollups interact efficiently?\n4. **Economic Sustainability**: What long-term revenue models support based rollup development?\n\n### 9.3 Adoption Barriers\n\n- **Incumbent Advantage**: Established rollups with centralized sequencers have significant network effects\n- **Developer Familiarity**: Most L2 developers are trained on centralized sequencer models\n- **Short-term UX**: Current latency disadvantages may deter user adoption\n- **Ecosystem Lock-in**: Applications deployed on existing rollups face migration costs\n\n---\n\n## 10. Conclusion\n\nBased rollups represent a principled approach to Layer 2 scaling that prioritizes Ethereum alignment and decentralization over raw performance metrics. By delegating sequencing to Ethereum's validator set, based rollups inherit the network's battle-tested security properties while eliminating the centralization risks inherent in dedicated sequencer infrastructure.\n\nThe primary trade-off\u2014increased confirmation latency\u2014is increasingly addressable through preconfirmation mechanisms that leverage proposer commitments to provide fast, credible transaction guarantees. As these systems mature, based rollups may achieve competitive latency while maintaining their decentralization advantages.\n\nTaiko's successful mainnet launch demonstrates the technical viability of based rollup architecture, while ongoing research into preconfirmations, MEV redistribution, and cross-rollup composability suggests a rich development trajectory. The based rollup model aligns with Ethereum's long-term vision of a decentralized settlement layer supporting diverse execution environments.\n\nFor applications prioritizing censorship resistance, liveness guarantees, and philosophical alignment with Ethereum's values, based rollups offer a compelling alternative to centralized sequencer architectures. As the ecosystem matures and latency solutions deploy, based rollups may emerge as the preferred architecture for security-conscious applications and Ethereum-native protocols.\n\nThe evolution of based rollups will likely be shaped by three key developments: the maturation of preconfirmation infrastructure, the economic sustainability of alternative revenue models, and the broader adoption of Ethereum's rollup-centric roadmap. Projects and researchers working at this frontier are laying the groundwork for a more decentralized, resilient, and Ethereum-aligned Layer 2 ecosystem.\n\n---\n\n## References\n\n1. Drake, J. (2023). \"Based rollups\u2014superpowers from L1 sequencing.\" Ethereum Research Forum.\n\n2. Buterin, V. (2020). \"A rollup-centric ethereum roadmap.\" Ethereum Magicians Forum.\n\n3. Taiko Labs. (2024). \"Taiko Protocol Specification.\" Technical Documentation.\n\n4. Ethereum Foundation. (2024). \"EIP-4844: Shard Blob Transactions.\" Ethereum Improvement Proposals.\n\n5. Flashbots. (2023). \"MEV-Share: Programmable Privacy for MEV.\" Research Publication.\n\n6. Espresso Systems. (2023). \"Espresso Sequencer: Decentralized Sequencing for Rollups.\" Technical Whitepaper.\n\n7. Drake, J. (2024). \"Based preconfirmations.\" Ethereum Research Forum.\n\n8. L2Beat. (2024). \"Layer 2 Risk Analysis.\" https://l2beat.com\n\n9. Gudgeon, L., et al. (2020). \"SoK: Layer-Two Blockchain Protocols.\" Financial Cryptography and Data Security.\n\n10. Daian, P., et al. (2020). \"Flash Boys 2.0: Frontrunning in Decentralized Exchanges.\" IEEE S&P.\n\n---\n\n*Word Count: ~4,200*\n\n*Last Updated: December 2024*"
}